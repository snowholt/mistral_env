"""
Simple Voice WebSocket Endpoint for Real-time Voice Chat.

This endpoint provides a streamlined, ultra-fast voice conversation interface
using Edge TTS and the SimpleVoiceService for maximum speed (<2 seconds).

Features:
- Simplified parameter set (language, voice_type only)
- Direct Edge TTS integration via SimpleVoiceService
- No complex configuration or session management
- Target response time: <2 seconds
- Arabic and English support only

Author: BeautyAI Framework
Date: 2025-07-23
"""

import asyncio
import json
import logging
import time
import uuid
from typing import Dict, Any, Optional
from pathlib import Path
import base64
import tempfile

from fastapi import APIRouter, WebSocket, WebSocketDisconnect, Query
from starlette.websockets import WebSocketState

from ...services.voice.conversation.simple_voice_service import SimpleVoiceService

logger = logging.getLogger(__name__)

websocket_simple_voice_router = APIRouter(prefix="/ws", tags=["simple-voice-chat"])

# Active WebSocket connections
simple_voice_connections: Dict[str, Dict[str, Any]] = {}


class SimpleVoiceWebSocketManager:
    """
    Lightweight WebSocket manager for simple voice conversations.
    
    Features:
    - Minimal connection tracking
    - Direct service integration  
    - Fast cleanup and error handling
    - No complex session management
    """
    
    def __init__(self):
        self.voice_service = SimpleVoiceService()
        self._service_initialized = False
        
    async def _ensure_service_initialized(self):
        """Ensure the voice service is initialized."""
        if not self._service_initialized:
            logger.info("Initializing SimpleVoiceService...")
            await self.voice_service.initialize()
            self._service_initialized = True
            logger.info("‚úÖ SimpleVoiceService initialized successfully")
    
    async def connect(
        self, 
        websocket: WebSocket, 
        connection_id: str,
        language: str,
        voice_type: str,
        session_id: str = None
    ) -> bool:
        """Accept connection with minimal setup."""
        try:
            await websocket.accept()
            
            # Ensure voice service is ready
            await self._ensure_service_initialized()
            
            # Store connection info with minimal state
            connection_state = {
                "websocket": websocket,
                "language": language,  # Fixed: no auto-detection
                "voice_type": voice_type,  # Fixed: male/female
                "session_id": session_id or f"simple_{connection_id}",
                "connected_at": time.time(),
                "message_count": 0
            }
            
            simple_voice_connections[connection_id] = connection_state
            
            logger.info(f"‚úÖ Simple voice WebSocket connected: {connection_id} (lang: {language}, voice: {voice_type})")
            
            # Send connection confirmation directly to websocket
            welcome_msg = {
                "type": "connection_established",
                "success": True,
                "connection_id": connection_id,
                "session_id": connection_state["session_id"],
                "timestamp": time.time(),
                "message": "Simple voice chat WebSocket connected successfully",
                "config": {
                    "language": language,
                    "voice_type": voice_type,
                    "target_response_time": "< 2 seconds"
                }
            }
            await websocket.send_text(json.dumps(welcome_msg))
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Failed to establish simple voice WebSocket connection {connection_id}: {e}")
            return False
    
    async def disconnect(self, connection_id: str):
        """Quick cleanup on disconnect."""
        if connection_id in simple_voice_connections:
            connection_info = simple_voice_connections[connection_id]
            session_duration = time.time() - connection_info["connected_at"]
            message_count = connection_info["message_count"]
            
            logger.info(f"üîå Simple voice WebSocket disconnected: {connection_id} (duration: {session_duration:.1f}s, messages: {message_count})")
            
            # Clean up connection
            del simple_voice_connections[connection_id]
            
        # Clean up voice service if no active connections
        if not simple_voice_connections:
            logger.info("No active simple voice connections, cleaning up...")
            await self._cleanup_service()
    
    async def _cleanup_service(self):
        """Clean up voice service when no active connections."""
        try:
            # Wait a bit before cleanup in case of quick reconnections
            await asyncio.sleep(1)  # Reduced wait time for testing
            if not simple_voice_connections and self._service_initialized:
                await self.voice_service.cleanup()
                self._service_initialized = False
                logger.info("‚úÖ SimpleVoiceService cleaned up")
        except Exception as e:
            logger.error(f"‚ùå Error during simple voice service cleanup: {e}")
    
    async def send_message(self, connection_id: str, message: Dict[str, Any]) -> bool:
        """Send a message to a specific WebSocket connection."""
        if connection_id not in simple_voice_connections:
            logger.warning(f"‚ö†Ô∏è Attempted to send message to non-existent connection: {connection_id}")
            return False
        
        connection = simple_voice_connections[connection_id]
        websocket = connection["websocket"]
        
        try:
            if websocket.client_state == WebSocketState.CONNECTED:
                await websocket.send_text(json.dumps(message))
                return True
            else:
                logger.warning(f"‚ö†Ô∏è Simple voice WebSocket connection {connection_id} is not connected")
                return False
        except Exception as e:
            logger.error(f"‚ùå Failed to send message to simple voice connection {connection_id}: {e}")
            await self.disconnect(connection_id)
            return False
    
    async def process_audio_message(
        self,
        connection_id: str,
        audio_data: bytes
    ) -> Dict[str, Any]:
        """Process audio with SimpleVoiceService for maximum speed."""
        if connection_id not in simple_voice_connections:
            return {"success": False, "error": "Connection not found"}
        
        connection = simple_voice_connections[connection_id]
        language = connection["language"]
        voice_type = connection["voice_type"]
        session_id = connection["session_id"]
        
        start_time = time.time()
        
        try:
            # Update message count
            connection["message_count"] += 1
            
            logger.info(f"üé§ Processing audio message {connection['message_count']} for {connection_id} (lang: {language}, voice: {voice_type})")
            
            # Send processing started message
            await self.send_message(connection_id, {
                "type": "processing_started",
                "success": True,
                "timestamp": time.time(),
                "message": "Processing your audio..."
            })
            
            # Use SimpleVoiceService for fast processing
            # Note: For now we'll use a simplified flow since the service has placeholders
            # In a real implementation, this would call the full voice processing pipeline
            
            # Save audio to temporary file for processing
            with tempfile.NamedTemporaryFile(suffix=".webm", delete=False) as temp_file:
                temp_file.write(audio_data)
                temp_audio_path = temp_file.name
            
            try:
                # Process with SimpleVoiceService
                # Note: The current service has placeholder implementations
                # This will be replaced with actual processing when services are fully integrated
                
                # For now, create a mock response to test the WebSocket flow
                result = await self._mock_voice_processing(temp_audio_path, language, voice_type)
                
                processing_time = time.time() - start_time
                
                if result["success"]:
                    # Prepare response
                    response_data = {
                        "type": "voice_response",
                        "success": True,
                        "audio_base64": result.get("audio_base64"),
                        "transcription": result.get("transcription", ""),
                        "response_text": result.get("response_text", ""),
                        "language": language,
                        "voice_type": voice_type,
                        "response_time_ms": int(processing_time * 1000),
                        "session_id": session_id,
                        "message_count": connection["message_count"],
                        "timestamp": time.time()
                    }
                    
                    # Send the response
                    await self.send_message(connection_id, response_data)
                    
                    logger.info(f"‚úÖ Simple voice processing completed in {processing_time:.2f}s for {connection_id}")
                    return {"success": True, "processing_time": processing_time}
                
                else:
                    # Processing failed
                    error_msg = result.get("error", "Voice processing failed")
                    await self.send_message(connection_id, {
                        "type": "error",
                        "success": False,
                        "error_code": "PROCESSING_FAILED",
                        "message": error_msg,
                        "retry_suggested": True,
                        "response_time_ms": int((time.time() - start_time) * 1000),
                        "timestamp": time.time()
                    })
                    return {"success": False, "error": error_msg}
            
            finally:
                # Clean up temporary file
                try:
                    Path(temp_audio_path).unlink()
                except Exception as cleanup_error:
                    logger.warning(f"‚ö†Ô∏è Failed to cleanup temp file {temp_audio_path}: {cleanup_error}")
        
        except Exception as e:
            processing_time = time.time() - start_time
            logger.error(f"‚ùå Error processing simple voice message for {connection_id}: {e}")
            
            await self.send_message(connection_id, {
                "type": "error",
                "success": False,
                "error_code": "INTERNAL_ERROR",
                "message": f"Processing error: {str(e)}",
                "retry_suggested": True,
                "response_time_ms": int(processing_time * 1000),
                "timestamp": time.time()
            })
            return {"success": False, "error": str(e)}
    
    async def _mock_voice_processing(self, audio_path: str, language: str, voice_type: str) -> Dict[str, Any]:
        """
        Mock voice processing for testing the WebSocket flow.
        This will be replaced with actual SimpleVoiceService integration.
        """
        try:
            # Generate mock response based on language
            if language == "ar":
                transcription = "ŸÖÿ±ÿ≠ÿ®ÿßÿå ŸÉŸäŸÅ ÿ≠ÿßŸÑŸÉÿü"
                response_text = "ÿ£ŸáŸÑÿßŸã Ÿàÿ≥ŸáŸÑÿßŸã! ÿ£ŸÜÿß ÿ®ÿÆŸäÿ±ÿå ÿ¥ŸÉÿ±ÿßŸã ŸÑŸÉ. ŸÉŸäŸÅ ŸäŸÖŸÉŸÜŸÜŸä ŸÖÿ≥ÿßÿπÿØÿ™ŸÉ ÿßŸÑŸäŸàŸÖÿü"
            else:  # English
                transcription = "Hello, how are you?"
                response_text = "Hello! I'm doing well, thank you. How can I help you today?"
            
            # Generate mock audio using SimpleVoiceService
            audio_output_path = await self.voice_service.text_to_speech(
                text=response_text,
                language=language,
                gender=voice_type
            )
            
            # Read audio file and encode to base64
            if audio_output_path and audio_output_path.exists():
                with open(audio_output_path, "rb") as audio_file:
                    audio_bytes = audio_file.read()
                
                audio_base64 = base64.b64encode(audio_bytes).decode("utf-8")
                
                # Clean up the audio file
                audio_output_path.unlink()
                
                return {
                    "success": True,
                    "transcription": transcription,
                    "response_text": response_text,
                    "audio_base64": audio_base64,
                    "audio_size_bytes": len(audio_bytes)
                }
            else:
                logger.error("‚ùå Failed to generate audio file")
                return {
                    "success": False,
                    "error": "Failed to generate audio response"
                }
        
        except Exception as e:
            logger.error(f"‚ùå Mock voice processing failed: {e}")
            return {
                "success": False,
                "error": f"Mock processing failed: {str(e)}"
            }


# Global WebSocket manager instance
simple_ws_manager = SimpleVoiceWebSocketManager()


@websocket_simple_voice_router.websocket("/simple-voice-chat")
async def websocket_simple_voice_chat(
    websocket: WebSocket,
    # Simplified parameters only
    language: str = Query("ar", description="Language: ar (Arabic) or en (English)"),
    voice_type: str = Query("female", description="Voice type: male or female"),
    session_id: Optional[str] = Query(None, description="Optional session ID"),
):
    """
    üöÄ Ultra-Fast Voice Chat WebSocket
    
    Simplified real-time voice conversation optimized for speed:
    - Arabic and English support only
    - No auto-detection or complex parameters
    - Target <2 second response time
    - Direct Edge TTS integration
    
    üéØ **Performance Goals:**
    - End-to-End Response: <2 seconds (audio in ‚Üí audio out)
    - Connection Overhead: Minimal parameters and setup
    - Simplicity: No complex configuration or session management
    - Languages: Arabic and English only
    
    üì° **Message Flow:**
    
    **Input (Client ‚Üí Server):**
    - Binary messages: Audio data (WebM, WAV, MP3)
    
    **Output (Server ‚Üí Client):**
    ```json
    {
        "type": "voice_response",
        "success": true,
        "audio_base64": "UklGRi4gAABXQVZFZm10...",
        "transcription": "ŸÖÿ±ÿ≠ÿ®ÿßÿå ŸÉŸäŸÅ ÿ≠ÿßŸÑŸÉÿü",
        "response_text": "ÿ£ŸáŸÑÿß Ÿàÿ≥ŸáŸÑÿß! ÿ£ŸÜÿß ÿ®ÿÆŸäÿ±ÿå ÿ¥ŸÉÿ±ÿß ŸÑŸÉ",
        "language": "ar",
        "voice_type": "female",
        "response_time_ms": 1250,
        "session_id": "simple_session_123"
    }
    ```
    
    üöÄ **Usage Example:**
    ```javascript
    const ws = new WebSocket('ws://localhost:8000/ws/simple-voice-chat?language=ar&voice_type=female');
    
    ws.onmessage = (event) => {
        const response = JSON.parse(event.data);
        if (response.type === 'voice_response' && response.audio_base64) {
            // Play received audio
            const audioBlob = base64ToBlob(response.audio_base64, 'audio/wav');
            const audioUrl = URL.createObjectURL(audioBlob);
            new Audio(audioUrl).play();
        }
    };
    
    // Send audio
    ws.send(audioData); // Send binary audio data
    ```
    """
    
    # Validate parameters
    if language not in ["ar", "en"]:
        await websocket.close(code=1003, reason="Invalid language. Supported: ar, en")
        return
    
    if voice_type not in ["male", "female"]:
        await websocket.close(code=1003, reason="Invalid voice_type. Supported: male, female")
        return
    
    # Generate unique connection ID
    connection_id = str(uuid.uuid4())
    
    logger.info(f"üé§ New simple voice WebSocket connection: {connection_id} (lang: {language}, voice: {voice_type})")
    
    # Establish connection
    connected = await simple_ws_manager.connect(
        websocket, 
        connection_id, 
        language, 
        voice_type, 
        session_id
    )
    
    if not connected:
        await websocket.close(code=1000, reason="Failed to establish connection")
        return
    
    try:
        while True:
            # Wait for message from client
            message = await websocket.receive()
            
            if message["type"] == "websocket.disconnect":
                break
            
            elif message["type"] == "websocket.receive":
                if "bytes" in message:
                    # Audio data received
                    audio_data = message["bytes"]
                    
                    if len(audio_data) > 0:
                        logger.info(f"üéµ Received audio data: {len(audio_data)} bytes from {connection_id}")
                        
                        # Process audio message for fast response
                        await simple_ws_manager.process_audio_message(
                            connection_id,
                            audio_data
                        )
                    else:
                        logger.warning(f"‚ö†Ô∏è Received empty audio data from {connection_id}")
                
                elif "text" in message:
                    # Control message received
                    try:
                        control_msg = json.loads(message["text"])
                        
                        if control_msg.get("type") == "ping":
                            # Respond to ping
                            await simple_ws_manager.send_message(connection_id, {
                                "type": "pong",
                                "timestamp": time.time()
                            })
                        
                        else:
                            logger.warning(f"‚ö†Ô∏è Unknown control message type: {control_msg.get('type')} from {connection_id}")
                    
                    except json.JSONDecodeError:
                        logger.warning(f"‚ö†Ô∏è Invalid JSON in text message from {connection_id}")
    
    except WebSocketDisconnect:
        logger.info(f"üîå Simple voice WebSocket disconnected: {connection_id}")
    
    except Exception as e:
        logger.error(f"‚ùå Simple voice WebSocket error for {connection_id}: {e}")
    
    finally:
        # Clean up connection
        await simple_ws_manager.disconnect(connection_id)


@websocket_simple_voice_router.get("/simple-voice-chat/status")
async def get_simple_voice_status():
    """Get simple voice service status."""
    active_connections_info = []
    
    for conn_id, info in simple_voice_connections.items():
        active_connections_info.append({
            "connection_id": conn_id,
            "session_id": info.get("session_id", f"session_{conn_id}"),
            "language": info.get("language", "ar"),
            "voice_type": info.get("voice_type", "female"),
            "connected_at": info.get("connected_at", time.time()),
            "duration_seconds": time.time() - info.get("connected_at", time.time()),
            "message_count": info.get("message_count", 0)
        })
    
    return {
        "service": "simple_voice_chat",
        "status": "available",
        "active_connections": len(simple_voice_connections),
        "connections": active_connections_info,
        "performance": {
            "target_response_time": "< 2 seconds",
            "supported_languages": ["ar", "en"],
            "voice_types": ["male", "female"],
            "engine": "Edge TTS via SimpleVoiceService"
        },
        "features": [
            "Ultra-fast voice responses",
            "Simplified parameter set",
            "No complex configuration",
            "Direct Edge TTS integration",
            "Arabic and English only"
        ],
        "audio_formats": {
            "input": ["webm", "wav", "mp3"],
            "output": ["wav"]
        },
        "comparison_with_advanced": {
            "simple_endpoint": {
                "route": "/ws/simple-voice-chat",
                "parameters": 3,
                "response_time": "< 2 seconds",
                "memory_usage": "< 50MB",
                "languages": "ar, en only",
                "features": "Voice chat only"
            },
            "advanced_endpoint": {
                "route": "/ws/voice-conversation", 
                "parameters": "20+",
                "response_time": "5-8 seconds",
                "memory_usage": "3GB+",
                "languages": "Auto-detection + many",
                "features": "Voice cloning, filtering, etc."
            }
        }
    }
