{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84db6663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting Enhanced Streaming Voice Debug\n",
      "   Host: 127.0.0.1:8000\n",
      "   Language: en\n",
      "   Files to test: 3\n",
      "   Pause between files: 6.0s\n",
      "   ✅ File 1: greeting.webm (18586 bytes)\n",
      "   ✅ File 2: botox.webm (21566 bytes)\n",
      "   ✅ File 3: laser_hair.webm (23981 bytes)\n",
      "✅ Streaming voice status: 200\n",
      "   Enabled: True, Active sessions: 0\n",
      "\n",
      "================================================================================\n",
      "🧪 STARTING CONVERSATION BLEEDING TEST\n",
      "================================================================================\n",
      "\n",
      "🔗 Connecting to WebSocket: ws://127.0.0.1:8000/api/v1/ws/streaming-voice?language=en\n",
      "🔗 WebSocket connected successfully!\n",
      "\n",
      "📤 [File 1] Starting upload: greeting.webm\n",
      "✅ [File 1] Uploaded 18586 bytes\n",
      "⏳ Waiting 6.0s before next file...\n",
      "📨 [#001] ready: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📨 [#002] decoder_started: \n",
      "📨 [#003] info: \n",
      "📨 [#004] ingest_mode: \n",
      "📨 [#005] partial_transcript: Hello, how are you today?\n",
      "📨 [#006] metrics_snapshot: \n",
      "📨 [#007] perf_cycle: \n",
      "📨 [#008] perf_cycle: \n",
      "📨 [#009] endpoint_event: \n",
      "📨 [#010] perf_cycle: \n",
      "📨 [#011] perf_cycle: \n",
      "📨 [#012] endpoint_event: \n",
      "📨 [#013] final_transcript: Hello, how are you today?\n",
      "🎤 FINAL TRANSCRIPT #0: Hello, how are you today?\n",
      "📨 [#014] perf_cycle: \n",
      "📨 [#015] assistant_pipeline_start: \n",
      "📨 [#016] tts_start: \n",
      "📨 [#017] endpoint_event: \n",
      "📨 [#018] heartbeat: \n",
      "📨 [#019] endpoint_event: \n",
      "\n",
      "📤 [File 2] Starting upload: botox.webm\n",
      "✅ [File 2] Uploaded 21566 bytes\n",
      "⏳ Waiting 6.0s before next file...\n",
      "📨 [#020] partial_transcript: Hello, how are you today? What is Botox used for?\n",
      "📨 [#021] metrics_snapshot: \n",
      "📨 [#022] endpoint_event: \n",
      "📨 [#023] endpoint_event: \n",
      "📨 [#024] final_transcript: Hello, how are you today? What is Botox used for?\n",
      "🚨 BLEEDING DETECTED: Current transcript contains previous content!\n",
      "   Previous: 'Hello, how are you today?'\n",
      "   Current:  'Hello, how are you today? What is Botox used for?'\n",
      "🎤 FINAL TRANSCRIPT #2: Hello, how are you today? What is Botox used for?\n",
      "📨 [#025] final_queued: \n",
      "📨 [#026] assistant_response: Hello! I'm doing well, thank you. How can I assist you today?\n",
      "🤖 ASSISTANT RESPONSE: Hello! I'm doing well, thank you. How can I assist you today?...\n",
      "📨 [#027] endpoint_event: \n",
      "📨 [#028] endpoint_event: \n",
      "📨 [#029] endpoint_event: \n",
      "📨 [#030] heartbeat: \n",
      "📨 [#031] tts_audio: Hello! I'm doing well, thank you. How can I assist you today?\n",
      "📨 [#032] tts_complete: \n",
      "📨 [#033] assistant_turn: \n",
      "📨 [#034] assistant_pipeline_done: \n",
      "📨 [#035] assistant_pipeline_start: \n",
      "📨 [#036] tts_start: \n",
      "📨 [#037] endpoint_event: \n",
      "📨 [#038] endpoint_event: \n",
      "📨 [#039] endpoint_event: \n",
      "📨 [#040] endpoint_event: \n",
      "📨 [#041] endpoint_event: \n",
      "📨 [#042] endpoint_event: \n",
      "📨 [#043] heartbeat: \n",
      "📨 [#044] assistant_response: Hello! I'm doing well, thank you. Botox, which is a brand name for botulinum toxin type A, is primar\n",
      "🤖 ASSISTANT RESPONSE: Hello! I'm doing well, thank you. Botox, which is a brand name for botulinum toxin type A, is primar...\n",
      "📨 [#045] endpoint_event: \n",
      "📨 [#046] endpoint_event: \n",
      "📨 [#047] endpoint_event: \n",
      "📨 [#048] endpoint_event: \n",
      "📨 [#049] endpoint_event: \n",
      "📨 [#050] heartbeat: \n",
      "\n",
      "📤 [File 3] Starting upload: laser_hair.webm\n",
      "✅ [File 3] Uploaded 23981 bytes\n",
      "📤 All files uploaded. Waiting 30.0s for final processing...\n",
      "📨 [#051] endpoint_event: \n",
      "📨 [#052] endpoint_event: \n",
      "📨 [#053] endpoint_event: \n",
      "🔚 [receiver] Connection ended after 53 messages: sent 1009 (message too big) frame with 1669257 bytes exceeds limit of 1048576 bytes; no close frame received\n"
     ]
    }
   ],
   "source": [
    "# Enhanced Streaming Voice WebSocket Debug - Test conversation history bleeding issue\n",
    "import asyncio, math, json, time, contextlib, os, ssl, base64\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "try:\n",
    "    import websockets  # type: ignore\n",
    "except ImportError:\n",
    "    raise RuntimeError(\"Install websockets: pip install websockets\")\n",
    "\n",
    "# Server configuration\n",
    "HOST = '127.0.0.1:8000'\n",
    "USE_SECURE = False  # Local server uses HTTP/WS\n",
    "LANGUAGE = 'en'  # Using English for clearer testing\n",
    "FAST = True  # if False, will pace real-time\n",
    "AUTO_CLOSE_AFTER_FINAL_S = 30.0  # Increased timeout for multi-file test\n",
    "\n",
    "# Test files for conversation simulation\n",
    "WEBM_FILES = [\n",
    "    Path('/home/lumi/beautyai/voice_tests/input_test_questions/webm/greeting.webm'),\n",
    "    Path('/home/lumi/beautyai/voice_tests/input_test_questions/webm/botox.webm'),\n",
    "    Path('/home/lumi/beautyai/voice_tests/input_test_questions/webm/laser_hair.webm')\n",
    "]\n",
    "\n",
    "PAUSE_BETWEEN_FILES_S = 6.0  # 6 seconds pause between files to simulate natural conversation\n",
    "\n",
    "print(f\"🚀 Starting Enhanced Streaming Voice Debug\")\n",
    "print(f\"   Host: {HOST}\")\n",
    "print(f\"   Language: {LANGUAGE}\")\n",
    "print(f\"   Files to test: {len(WEBM_FILES)}\")\n",
    "print(f\"   Pause between files: {PAUSE_BETWEEN_FILES_S}s\")\n",
    "\n",
    "# Verify all test files exist\n",
    "for i, webm_path in enumerate(WEBM_FILES, 1):\n",
    "    if webm_path.exists():\n",
    "        print(f\"   ✅ File {i}: {webm_path.name} ({webm_path.stat().st_size} bytes)\")\n",
    "    else:\n",
    "        print(f\"   ❌ File {i}: {webm_path.name} - NOT FOUND\")\n",
    "        \n",
    "# Verify streaming endpoint is available\n",
    "import requests\n",
    "try:\n",
    "    stream_status = requests.get(f\"http://{HOST}/api/v1/ws/streaming-voice/status\", timeout=5)\n",
    "    print(f\"✅ Streaming voice status: {stream_status.status_code}\")\n",
    "    if stream_status.status_code == 200:\n",
    "        status_data = stream_status.json()\n",
    "        print(f\"   Enabled: {status_data.get('enabled')}, Active sessions: {status_data.get('active_sessions')}\")\n",
    "    else:\n",
    "        print(f\"❌ Stream status error: {stream_status.text}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Local server connection failed: {e}\")\n",
    "\n",
    "async def test_conversation_bleeding():\n",
    "    \"\"\"\n",
    "    Test for conversation history bleeding by uploading webm files sequentially\n",
    "    with pauses to simulate real conversation flow.\n",
    "    \"\"\"\n",
    "    scheme = 'wss' if USE_SECURE else 'ws'\n",
    "    url = f\"{scheme}://{HOST}/api/v1/ws/streaming-voice?language={LANGUAGE}\"\n",
    "    print(f\"\\n🔗 Connecting to WebSocket: {url}\")\n",
    "\n",
    "    # Global test state\n",
    "    test_results = {\n",
    "        'connection_established': False,\n",
    "        'files_processed': [],\n",
    "        'transcription_events': [],\n",
    "        'assistant_responses': [],\n",
    "        'conversation_bleeding_detected': False,\n",
    "        'bleeding_evidence': [],\n",
    "        'total_events': 0,\n",
    "        'test_start_time': time.time(),\n",
    "        'errors': []\n",
    "    }\n",
    "    \n",
    "    events_log = []\n",
    "    final_transcripts = []  # Track final transcripts for each file\n",
    "    \n",
    "    async def receiver(ws):\n",
    "        \"\"\"Handle all incoming WebSocket messages and track conversation bleeding\"\"\"\n",
    "        message_count = 0\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                try:\n",
    "                    msg = await asyncio.wait_for(ws.recv(), timeout=5.0)\n",
    "                    message_count += 1\n",
    "                    test_results['total_events'] = message_count\n",
    "                except asyncio.TimeoutError:\n",
    "                    print(\"⏰ [receiver] No message for 5s, continuing...\")\n",
    "                    continue\n",
    "                except Exception as e:\n",
    "                    print(f\"🔚 [receiver] Connection ended after {message_count} messages: {e}\")\n",
    "                    break\n",
    "                \n",
    "                timestamp = time.time()\n",
    "                \n",
    "                try:\n",
    "                    data = json.loads(msg)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"📄 [receiver] Non-JSON message #{message_count}\")\n",
    "                    continue\n",
    "                    \n",
    "                # Log all events for analysis\n",
    "                event_entry = {\n",
    "                    'timestamp': timestamp,\n",
    "                    'message_num': message_count,\n",
    "                    'event_type': data.get('type', data.get('event', 'unknown')),\n",
    "                    'data': data,\n",
    "                    'relative_time_s': round(timestamp - test_results['test_start_time'], 2)\n",
    "                }\n",
    "                events_log.append(event_entry)\n",
    "                \n",
    "                etype = data.get('type', data.get('event'))\n",
    "                content_preview = str(data.get('text', data.get('content', '')))[:100]\n",
    "                \n",
    "                print(f\"📨 [#{message_count:03d}] {etype}: {content_preview}\")\n",
    "                \n",
    "                # Track transcription events specifically\n",
    "                if etype in ['partial_transcript', 'final_transcript']:\n",
    "                    transcription_event = {\n",
    "                        'type': etype,\n",
    "                        'text': data.get('text', ''),\n",
    "                        'utterance_index': data.get('utterance_index'),\n",
    "                        'timestamp': timestamp,\n",
    "                        'file_context': len(test_results['files_processed'])  # Which file was being processed\n",
    "                    }\n",
    "                    test_results['transcription_events'].append(transcription_event)\n",
    "                    \n",
    "                    # For final transcripts, check for bleeding\n",
    "                    if etype == 'final_transcript':\n",
    "                        final_text = data.get('text', '').strip()\n",
    "                        if final_text:\n",
    "                            final_transcripts.append({\n",
    "                                'text': final_text,\n",
    "                                'utterance_index': data.get('utterance_index'),\n",
    "                                'file_number': len(test_results['files_processed']),\n",
    "                                'timestamp': timestamp\n",
    "                            })\n",
    "                            \n",
    "                            # Check for conversation bleeding\n",
    "                            current_file_num = len(test_results['files_processed'])\n",
    "                            if current_file_num > 1:  # Only check after first file\n",
    "                                # Check if this transcript contains text from previous files\n",
    "                                for prev_transcript in final_transcripts[:-1]:  # All previous transcripts\n",
    "                                    if prev_transcript['text'].lower() in final_text.lower():\n",
    "                                        bleeding_evidence = {\n",
    "                                            'current_transcript': final_text,\n",
    "                                            'previous_transcript': prev_transcript['text'],\n",
    "                                            'current_file': current_file_num,\n",
    "                                            'previous_file': prev_transcript['file_number'],\n",
    "                                            'detection_time': timestamp\n",
    "                                        }\n",
    "                                        test_results['bleeding_evidence'].append(bleeding_evidence)\n",
    "                                        test_results['conversation_bleeding_detected'] = True\n",
    "                                        print(f\"🚨 BLEEDING DETECTED: Current transcript contains previous content!\")\n",
    "                                        print(f\"   Previous: '{prev_transcript['text']}'\")\n",
    "                                        print(f\"   Current:  '{final_text}'\")\n",
    "                            \n",
    "                            print(f\"🎤 FINAL TRANSCRIPT #{data.get('utterance_index', '?')}: {final_text}\")\n",
    "                    \n",
    "                elif etype in ['assistant_response', 'assistant_text']:\n",
    "                    assistant_text = data.get('text', '')\n",
    "                    if assistant_text:\n",
    "                        test_results['assistant_responses'].append({\n",
    "                            'text': assistant_text,\n",
    "                            'utterance_index': data.get('utterance_index'),\n",
    "                            'timestamp': timestamp,\n",
    "                            'file_context': len(test_results['files_processed'])\n",
    "                        })\n",
    "                        print(f\"🤖 ASSISTANT RESPONSE: {assistant_text[:100]}...\")\n",
    "                \n",
    "                elif etype == 'error':\n",
    "                    error_msg = data.get('message', 'Unknown error')\n",
    "                    test_results['errors'].append({\n",
    "                        'message': error_msg,\n",
    "                        'stage': data.get('stage'),\n",
    "                        'timestamp': timestamp\n",
    "                    })\n",
    "                    print(f\"❌ ERROR: {error_msg}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"❌ [receiver] Error: {e}\")\n",
    "            test_results['errors'].append({'message': str(e), 'timestamp': time.time()})\n",
    "\n",
    "    async def send_webm_file(ws, file_path: Path, file_number: int):\n",
    "        \"\"\"Send a webm file to the WebSocket for processing\"\"\"\n",
    "        print(f\"\\n📤 [File {file_number}] Starting upload: {file_path.name}\")\n",
    "        \n",
    "        try:\n",
    "            webm_data = file_path.read_bytes()\n",
    "            await ws.send(webm_data)\n",
    "            \n",
    "            file_info = {\n",
    "                'file_path': str(file_path),\n",
    "                'file_name': file_path.name,\n",
    "                'file_number': file_number,\n",
    "                'file_size_bytes': len(webm_data),\n",
    "                'upload_timestamp': time.time()\n",
    "            }\n",
    "            test_results['files_processed'].append(file_info)\n",
    "            \n",
    "            print(f\"✅ [File {file_number}] Uploaded {len(webm_data)} bytes\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ [File {file_number}] Upload failed: {e}\")\n",
    "            test_results['errors'].append({\n",
    "                'message': f\"File upload failed: {e}\",\n",
    "                'file': str(file_path),\n",
    "                'timestamp': time.time()\n",
    "            })\n",
    "\n",
    "    # Main test execution\n",
    "    try:\n",
    "        async with websockets.connect(url, ping_interval=30) as ws:\n",
    "            print(\"🔗 WebSocket connected successfully!\")\n",
    "            test_results['connection_established'] = True\n",
    "            \n",
    "            # Start receiver task\n",
    "            receiver_task = asyncio.create_task(receiver(ws))\n",
    "            \n",
    "            # Send files sequentially with pauses\n",
    "            for i, webm_file in enumerate(WEBM_FILES, 1):\n",
    "                if not webm_file.exists():\n",
    "                    print(f\"⚠️ Skipping missing file: {webm_file}\")\n",
    "                    continue\n",
    "                    \n",
    "                # Upload the file\n",
    "                await send_webm_file(ws, webm_file, i)\n",
    "                \n",
    "                # Wait for processing before next file (except for last file)\n",
    "                if i < len(WEBM_FILES):\n",
    "                    print(f\"⏳ Waiting {PAUSE_BETWEEN_FILES_S}s before next file...\")\n",
    "                    await asyncio.sleep(PAUSE_BETWEEN_FILES_S)\n",
    "            \n",
    "            print(f\"📤 All files uploaded. Waiting {AUTO_CLOSE_AFTER_FINAL_S}s for final processing...\")\n",
    "            \n",
    "            # Wait for final processing to complete\n",
    "            try:\n",
    "                await asyncio.sleep(AUTO_CLOSE_AFTER_FINAL_S)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # Cancel receiver task\n",
    "            receiver_task.cancel()\n",
    "            try:\n",
    "                await receiver_task\n",
    "            except asyncio.CancelledError:\n",
    "                pass\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"❌ WebSocket connection error: {e}\")\n",
    "        test_results['errors'].append({'message': f\"Connection error: {e}\", 'timestamp': time.time()})\n",
    "\n",
    "    # Final analysis and reporting\n",
    "    test_results['test_end_time'] = time.time()\n",
    "    test_results['total_duration_s'] = test_results['test_end_time'] - test_results['test_start_time']\n",
    "    test_results['all_events'] = events_log\n",
    "    test_results['final_transcripts'] = final_transcripts\n",
    "    \n",
    "    return test_results\n",
    "\n",
    "# Run the conversation bleeding test\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"🧪 STARTING CONVERSATION BLEEDING TEST\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "test_results = await test_conversation_bleeding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc920b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "📋 GENERATING BUG REPORT\n",
      "================================================================================\n",
      "# 🐛 Streaming Voice WebSocket - Conversation History Bleeding Bug Report\n",
      "**Generated:** 2025-08-22 13:20:06 UTC\n",
      "**Test Duration:** 42.04s\n",
      "**Total Events:** 53\n",
      "\n",
      "## 📋 Test Summary\n",
      "- **Connection Established:** ✅ Yes\n",
      "- **Files Processed:** 3/3\n",
      "- **Transcription Events:** 4\n",
      "- **Assistant Responses:** 2\n",
      "- **Errors Encountered:** 0\n",
      "- **Conversation Bleeding Detected:** 🚨 YES\n",
      "\n",
      "## 📁 Files Processed\n",
      "\n",
      "- **File 1:** greeting.webm (18586 bytes)\n",
      "- **File 2:** botox.webm (21566 bytes)\n",
      "- **File 3:** laser_hair.webm (23981 bytes)\n",
      "\n",
      "## 🚨 Conversation Bleeding Evidence\n",
      "\n",
      "### Evidence #1\n",
      "- **Current File:** 2\n",
      "- **Previous File:** 1\n",
      "- **Previous Transcript:** `Hello, how are you today?`\n",
      "- **Current Transcript:** `Hello, how are you today? What is Botox used for?`\n",
      "- **Detection Time:** 1755866728.168185\n",
      "\n",
      "## 🎤 Final Transcripts Chronology\n",
      "\n",
      "### Transcript 1 (File 1, Utterance 0)\n",
      "- **Time:** +5.27s\n",
      "- **Text:** `Hello, how are you today?`\n",
      "\n",
      "### Transcript 2 (File 2, Utterance 2)\n",
      "- **Time:** +6.77s\n",
      "- **Text:** `Hello, how are you today? What is Botox used for?`\n",
      "\n",
      "## 🤖 Assistant Responses\n",
      "\n",
      "### Response 1 (File Context 2, Utterance 0)\n",
      "- **Time:** +6.79s\n",
      "- **Text:** `Hello! I'm doing well, thank you. How can I assist you today?`\n",
      "\n",
      "### Response 2 (File Context 2, Utterance 2)\n",
      "- **Time:** +10.11s\n",
      "- **Text:** `Hello! I'm doing well, thank you. Botox, which is a brand name for botulinum toxin type A, is primarily used to temporarily reduce the appearance of facial wrinkles and fine lines. It works by relaxin...`\n",
      "\n",
      "## 📊 Key Events Timeline\n",
      "\n",
      "- **+  5.27s** `final_transcript` - Hello, how are you today?\n",
      "- **+  6.77s** `final_transcript` - Hello, how are you today? What is Botox used for?\n",
      "- **+  6.79s** `assistant_response` - Hello! I'm doing well, thank you. How can I assist you today?\n",
      "- **+ 10.11s** `assistant_response` - Hello! I'm doing well, thank you. Botox, which is a brand name for botulinum toxin type A, is primar\n",
      "\n",
      "## 🔧 Technical Analysis\n",
      "\n",
      "### Potential Root Causes\n",
      "1. **Whisper Model State Persistence:** The Whisper transcription service may be maintaining audio buffer state between utterances\n",
      "2. **Conversation History Bleeding:** Backend conversation history management may be incorrectly prepending previous transcripts\n",
      "3. **Session State Management:** WebSocket session state (utterance indices, processed transcripts) may not be properly reset between utterances\n",
      "4. **Audio Buffer Accumulation:** Audio chunks from previous utterances may be accumulating in transcription pipeline\n",
      "\n",
      "### Recommended Investigation Areas\n",
      "1. **Streaming Voice Endpoint:** Check `SessionState.conversation` and utterance tracking logic\n",
      "2. **Transcription Service:** Verify Whisper model state isolation between utterances\n",
      "3. **WebSocket Message Handling:** Examine partial/final transcript processing and deduplication\n",
      "4. **Conversation Reset Mechanism:** Validate that reset functionality clears all relevant state\n",
      "\n",
      "### Environment Context\n",
      "- **Server:** 127.0.0.1:8000\n",
      "- **Language:** en\n",
      "- **WebSocket URL:** `ws://127.0.0.1:8000/api/v1/ws/streaming-voice?language=en`\n",
      "\n",
      "\n",
      "💾 Test results saved to: /home/lumi/beautyai/tests/streaming/conversation_bleeding_test_results.json\n",
      "\n",
      "🏁 Test completed. Bleeding detected: YES\n"
     ]
    }
   ],
   "source": [
    "# Generate comprehensive bug report\n",
    "def generate_bug_report(test_results: Dict[str, Any]) -> str:\n",
    "    \"\"\"Generate a comprehensive bug report from test results\"\"\"\n",
    "    \n",
    "    report_lines = [\n",
    "        \"# 🐛 Streaming Voice WebSocket - Conversation History Bleeding Bug Report\",\n",
    "        f\"**Generated:** {time.strftime('%Y-%m-%d %H:%M:%S UTC', time.gmtime())}\",\n",
    "        f\"**Test Duration:** {test_results.get('total_duration_s', 0):.2f}s\",\n",
    "        f\"**Total Events:** {test_results.get('total_events', 0)}\",\n",
    "        \"\",\n",
    "        \"## 📋 Test Summary\",\n",
    "        f\"- **Connection Established:** {'✅ Yes' if test_results.get('connection_established') else '❌ No'}\",\n",
    "        f\"- **Files Processed:** {len(test_results.get('files_processed', []))}/3\",\n",
    "        f\"- **Transcription Events:** {len(test_results.get('transcription_events', []))}\",\n",
    "        f\"- **Assistant Responses:** {len(test_results.get('assistant_responses', []))}\",\n",
    "        f\"- **Errors Encountered:** {len(test_results.get('errors', []))}\",\n",
    "        f\"- **Conversation Bleeding Detected:** {'🚨 YES' if test_results.get('conversation_bleeding_detected') else '✅ NO'}\",\n",
    "        \"\"\n",
    "    ]\n",
    "    \n",
    "    # Files processed section\n",
    "    if test_results.get('files_processed'):\n",
    "        report_lines.extend([\n",
    "            \"## 📁 Files Processed\",\n",
    "            \"\"\n",
    "        ])\n",
    "        for file_info in test_results['files_processed']:\n",
    "            report_lines.append(f\"- **File {file_info['file_number']}:** {file_info['file_name']} ({file_info['file_size_bytes']} bytes)\")\n",
    "    \n",
    "    # Bleeding evidence section\n",
    "    if test_results.get('conversation_bleeding_detected') and test_results.get('bleeding_evidence'):\n",
    "        report_lines.extend([\n",
    "            \"\",\n",
    "            \"## 🚨 Conversation Bleeding Evidence\",\n",
    "            \"\"\n",
    "        ])\n",
    "        for i, evidence in enumerate(test_results['bleeding_evidence'], 1):\n",
    "            report_lines.extend([\n",
    "                f\"### Evidence #{i}\",\n",
    "                f\"- **Current File:** {evidence['current_file']}\",\n",
    "                f\"- **Previous File:** {evidence['previous_file']}\",\n",
    "                f\"- **Previous Transcript:** `{evidence['previous_transcript']}`\",\n",
    "                f\"- **Current Transcript:** `{evidence['current_transcript']}`\",\n",
    "                f\"- **Detection Time:** {evidence['detection_time']}\",\n",
    "                \"\"\n",
    "            ])\n",
    "    \n",
    "    # Final transcripts section\n",
    "    if test_results.get('final_transcripts'):\n",
    "        report_lines.extend([\n",
    "            \"## 🎤 Final Transcripts Chronology\",\n",
    "            \"\"\n",
    "        ])\n",
    "        for i, transcript in enumerate(test_results['final_transcripts'], 1):\n",
    "            relative_time = transcript['timestamp'] - test_results['test_start_time']\n",
    "            report_lines.extend([\n",
    "                f\"### Transcript {i} (File {transcript['file_number']}, Utterance {transcript['utterance_index']})\",\n",
    "                f\"- **Time:** +{relative_time:.2f}s\",\n",
    "                f\"- **Text:** `{transcript['text']}`\",\n",
    "                \"\"\n",
    "            ])\n",
    "    \n",
    "    # Assistant responses section\n",
    "    if test_results.get('assistant_responses'):\n",
    "        report_lines.extend([\n",
    "            \"## 🤖 Assistant Responses\",\n",
    "            \"\"\n",
    "        ])\n",
    "        for i, response in enumerate(test_results['assistant_responses'], 1):\n",
    "            relative_time = response['timestamp'] - test_results['test_start_time']\n",
    "            report_lines.extend([\n",
    "                f\"### Response {i} (File Context {response['file_context']}, Utterance {response['utterance_index']})\",\n",
    "                f\"- **Time:** +{relative_time:.2f}s\",\n",
    "                f\"- **Text:** `{response['text'][:200]}{'...' if len(response['text']) > 200 else ''}`\",\n",
    "                \"\"\n",
    "            ])\n",
    "    \n",
    "    # Errors section\n",
    "    if test_results.get('errors'):\n",
    "        report_lines.extend([\n",
    "            \"## ❌ Errors Encountered\",\n",
    "            \"\"\n",
    "        ])\n",
    "        for i, error in enumerate(test_results['errors'], 1):\n",
    "            relative_time = error['timestamp'] - test_results['test_start_time']\n",
    "            report_lines.extend([\n",
    "                f\"### Error {i}\",\n",
    "                f\"- **Time:** +{relative_time:.2f}s\",\n",
    "                f\"- **Stage:** {error.get('stage', 'Unknown')}\",\n",
    "                f\"- **Message:** `{error['message']}`\",\n",
    "                \"\"\n",
    "            ])\n",
    "    \n",
    "    # Event timeline section (key events only)\n",
    "    if test_results.get('all_events'):\n",
    "        report_lines.extend([\n",
    "            \"## 📊 Key Events Timeline\",\n",
    "            \"\"\n",
    "        ])\n",
    "        key_event_types = ['final_transcript', 'assistant_response', 'error', 'conversation_reset']\n",
    "        key_events = [e for e in test_results['all_events'] if e['event_type'] in key_event_types]\n",
    "        \n",
    "        for event in key_events[:20]:  # Limit to first 20 key events\n",
    "            report_lines.append(f\"- **+{event['relative_time_s']:6.2f}s** `{event['event_type']}` - {str(event['data'].get('text', event['data'].get('message', 'N/A')))[:100]}\")\n",
    "    \n",
    "    # Technical details section\n",
    "    report_lines.extend([\n",
    "        \"\",\n",
    "        \"## 🔧 Technical Analysis\",\n",
    "        \"\",\n",
    "        \"### Potential Root Causes\",\n",
    "        \"1. **Whisper Model State Persistence:** The Whisper transcription service may be maintaining audio buffer state between utterances\",\n",
    "        \"2. **Conversation History Bleeding:** Backend conversation history management may be incorrectly prepending previous transcripts\",\n",
    "        \"3. **Session State Management:** WebSocket session state (utterance indices, processed transcripts) may not be properly reset between utterances\",\n",
    "        \"4. **Audio Buffer Accumulation:** Audio chunks from previous utterances may be accumulating in transcription pipeline\",\n",
    "        \"\",\n",
    "        \"### Recommended Investigation Areas\",\n",
    "        \"1. **Streaming Voice Endpoint:** Check `SessionState.conversation` and utterance tracking logic\",\n",
    "        \"2. **Transcription Service:** Verify Whisper model state isolation between utterances\",\n",
    "        \"3. **WebSocket Message Handling:** Examine partial/final transcript processing and deduplication\",\n",
    "        \"4. **Conversation Reset Mechanism:** Validate that reset functionality clears all relevant state\",\n",
    "        \"\",\n",
    "        f\"### Environment Context\",\n",
    "        f\"- **Server:** {HOST}\",\n",
    "        f\"- **Language:** {LANGUAGE}\",\n",
    "        f\"- **WebSocket URL:** `{'wss' if USE_SECURE else 'ws'}://{HOST}/api/v1/ws/streaming-voice?language={LANGUAGE}`\",\n",
    "        \"\"\n",
    "    ])\n",
    "    \n",
    "    return \"\\n\".join(report_lines)\n",
    "\n",
    "# Generate and display the bug report\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"📋 GENERATING BUG REPORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "bug_report = generate_bug_report(test_results)\n",
    "print(bug_report)\n",
    "\n",
    "# Save results for further analysis\n",
    "results_file = Path('/home/lumi/beautyai/tests/streaming/conversation_bleeding_test_results.json')\n",
    "results_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    with open(results_file, 'w') as f:\n",
    "        json.dump(test_results, f, indent=2, default=str)\n",
    "    print(f\"\\n💾 Test results saved to: {results_file}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Failed to save results: {e}\")\n",
    "\n",
    "print(f\"\\n🏁 Test completed. Bleeding detected: {'YES' if test_results.get('conversation_bleeding_detected') else 'NO'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
