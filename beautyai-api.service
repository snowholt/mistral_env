[Unit]
Description=BeautyAI Inference API Server (Production)
After=network.target
Wants=network.target

[Service]
Type=simple
User=lumi
Group=lumi
WorkingDirectory=/home/lumi/beautyai/backend

# Load environment variables from production file
EnvironmentFile=-/home/lumi/beautyai/.env.production

# Core environment settings
Environment=PATH=/home/lumi/beautyai/backend/venv/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
Environment=PYTHONPATH=/home/lumi/beautyai/backend
Environment=CUDA_VISIBLE_DEVICES=0

# Voice streaming configuration
Environment=VOICE_STREAMING_ENABLED=1
Environment=VOICE_STREAMING_PHASE4=1
Environment=VOICE_STREAMING_FORCE_REAL=1
Environment=VOICE_STREAMING_DISABLE_MOCK=1
Environment=VOICE_STREAMING_DECODE_INTERVAL_MS=240
Environment=VOICE_STREAMING_WINDOW_SECONDS=6.0
Environment=VOICE_STREAMING_MIN_SILENCE_MS=480
Environment=VOICE_STREAMING_TOKEN_STABLE_MS=480
Environment=VOICE_STREAMING_MAX_UTTERANCE_MS=10000
Environment=VOICE_STREAMING_MIN_EMIT_CHARS=1
Environment=VOICE_STREAMING_LENIENT_FINAL=1
Environment=VOICE_STREAMING_LENIENT_FINAL_DELAY_SEC=0.8
Environment=VOICE_STREAMING_FORCE_FINAL_AFTER_SEC=12
Environment=VOICE_STREAMING_LOW_LATENCY_PRESET=1
Environment=UVICORN_RELOAD=0

ExecStart=/home/lumi/beautyai/backend/venv/bin/python /home/lumi/beautyai/backend/run_server.py
ExecReload=/bin/kill -HUP $MAINPID
KillMode=mixed
KillSignal=SIGINT
TimeoutStopSec=5
Restart=on-failure
RestartSec=3

# Security settings
NoNewPrivileges=yes
PrivateTmp=yes
ProtectSystem=strict
ReadWritePaths=/home/lumi/beautyai/backend
ProtectHome=read-only

# Resource limits
LimitNOFILE=65536
MemoryMax=32G

# Logging
StandardOutput=journal
StandardError=journal
SyslogIdentifier=beautyai-api

[Install]
WantedBy=multi-user.target
