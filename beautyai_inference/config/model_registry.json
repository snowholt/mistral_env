{
  
  "default_model": "qwen3-unsloth-q4ks",
  "models": {
    "qwen3-model": {
      "model_id": "Qwen/Qwen3-14B",
      "engine_type": "transformers",
      "quantization": "4bit",
      "dtype": "bfloat16",
      "max_new_tokens": 1024,
      "name": "qwen3-model",
      "description": "Qwen3 14B model (4-bit quantized) - Transformers engine",
      "model_architecture": "causal_lm",
      "custom_generation_params": {
        "temperature": 0.1,
        "top_p": 0.95,
        "do_sample": true,
        "repetition_penalty": 1.1
      }
    },
      
    "deepseek-r1-qwen-14b-multilingual": {
      "model_id": "lightblue/DeepSeek-R1-Distill-Qwen-14B-Multilingual",
      "engine_type": "transformers",
      "quantization": "4bit",
      "dtype": "bfloat16",
      "max_new_tokens": 1024,
      "name": "deepseek-r1-qwen-14b-multilingual",
      "description": "DeepSeek R1 Distill Qwen 14B Multilingual - Transformers engine",
      "model_architecture": "causal_lm",
      "custom_generation_params": {
        "temperature": 0.6,
        "top_p": 0.95,
        "do_sample": true,
        "repetition_penalty": 1.1
      }
    },

    "qwen3-official-q4km": {
      "model_id": "Qwen/Qwen3-14B-GGUF",
      "engine_type": "llama.cpp",
      "quantization": "Q4_K_M",
      "dtype": "float16",
      "model_filename": "Qwen3-14B-Q4_K_M.gguf",
      "tokenizer_model_id": "Qwen/Qwen3-14B",
      "max_new_tokens": 256,
      "name": "qwen3-official-q4km",
      "description": "Qwen3 14B Q4_K_M - Official GGUF (8.4GB) - LlamaCpp engine",
      "model_architecture": "causal_lm",
      "custom_generation_params": {
        "temperature": 0.1,
        "top_p": 0.8,
        "do_sample": true,
        "repetition_penalty": 1.05,
        "top_k": 10
      }
    },

    "qwen3-official-q6k": {
      "model_id": "Qwen/Qwen3-14B-GGUF",
      "engine_type": "llama.cpp",
      "quantization": "Q6_K",
      "dtype": "float16",
      "model_filename": "Qwen3-14B-Q6_K.gguf",
      "tokenizer_model_id": "Qwen/Qwen3-14B",
      "max_new_tokens": 256,
      "name": "qwen3-official-q6k",
      "description": "Qwen3 14B Q6_K - Official GGUF high quality (12GB) - LlamaCpp engine",
      "model_architecture": "causal_lm",
      "custom_generation_params": {
        "temperature": 0.1,
        "top_p": 0.8,
        "do_sample": true,
        "repetition_penalty": 1.05,
        "top_k": 10
      }
    },

    "qwen3-unsloth-q4ks": {
      "model_id": "unsloth/Qwen3-14B-GGUF",
      "engine_type": "llama.cpp",
      "quantization": "Q4_K_S",
      "dtype": "float16",
      "model_filename": "Qwen3-14B-Q4_K_S.gguf",
      "tokenizer_model_id": "Qwen/Qwen3-14B",
      "max_new_tokens": 256,
      "name": "qwen3-unsloth-q4ks",
      "description": "Qwen3 14B Q4_K_S - Unsloth optimized fastest (8.0GB) - LlamaCpp engine",
      "model_architecture": "causal_lm",
      "custom_generation_params": {
        "temperature": 0.1,
        "top_p": 0.8,
        "do_sample": true,
        "repetition_penalty": 1.05,
        "top_k": 10
      }
    },

    "qwen3-unsloth-q4km": {
      "model_id": "unsloth/Qwen3-14B-GGUF",
      "engine_type": "llama.cpp",
      "quantization": "Q4_K_M",
      "dtype": "float16",
      "model_filename": "Qwen3-14B-Q4_K_M.gguf",
      "tokenizer_model_id": "Qwen/Qwen3-14B",
      "max_new_tokens": 256,
      "name": "qwen3-unsloth-q4km",
      "description": "Qwen3 14B Q4_K_M - Unsloth optimized balanced (8.4GB) - LlamaCpp engine",
      "model_architecture": "causal_lm",
      "custom_generation_params": {
        "temperature": 0.1,
        "top_p": 0.8,
        "do_sample": true,
        "repetition_penalty": 1.05,
        "top_k": 10
      }
    },

    "qwen3-unsloth-q6k": {
      "model_id": "unsloth/Qwen3-14B-GGUF",
      "engine_type": "llama.cpp",
      "quantization": "Q6_K",
      "dtype": "float16",
      "model_filename": "Qwen3-14B-Q6_K.gguf",
      "tokenizer_model_id": "Qwen/Qwen3-14B",
      "max_new_tokens": 256,
      "name": "qwen3-unsloth-q6k",
      "description": "Qwen3 14B Q6_K - Unsloth optimized high quality (12GB) - LlamaCpp engine",
      "model_architecture": "causal_lm",
      "custom_generation_params": {
        "temperature": 0.1,
        "top_p": 0.8,
        "do_sample": true,
        "repetition_penalty": 1.05,
        "top_k": 10
      }
    },



    "bee1reason-arabic-q4ks": {
      "model_id": "mradermacher/Bee1reason-arabic-Qwen-14B-i1-GGUF",
      "engine_type": "llama.cpp",
      "quantization": "i1-Q4_K_S",
      "dtype": "float16",
      "max_new_tokens": 256,
      "name": "bee1reason-arabic-q4ks",
      "description": "Bee1reason Arabic Qwen 14B i1-Q4_K_S - Fast Arabic reasoning - LlamaCpp engine (cleaned)",
      "model_architecture": "causal_lm",
      "model_filename": "Bee1reason-arabic-Qwen-14B.i1-Q4_K_S.gguf",
      "blob_id": "334c5a6e68b4b18828cc3aeb771a22bd9bcbbca6d55c29ce507f3967c7db1af5",
      "custom_generation_params": {
        "temperature": 0.1,
        "top_p": 0.8,
        "do_sample": true,
        "repetition_penalty": 1.05,
        "top_k": 10
      }
    },

    "bee1reason-arabic-q4km-i1": {
      "model_id": "mradermacher/Bee1reason-arabic-Qwen-14B-i1-GGUF",
      "engine_type": "llama.cpp",
      "quantization": "i1-Q4_K_M",
      "dtype": "float16",
      "max_new_tokens": 256,
      "name": "bee1reason-arabic-q4km-i1",
      "description": "Bee1reason Arabic Qwen 14B i1-Q4_K_M - Balanced Arabic reasoning - LlamaCpp engine (cleaned)",
      "model_architecture": "causal_lm",
      "model_filename": "Bee1reason-arabic-Qwen-14B.i1-Q4_K_M.gguf",
      "blob_id": "b17a5d0aa671fe8fad0abdc9c9914386f9a5b73bc69366500ed8f99b371a4552",
      "custom_generation_params": {
        "temperature": 0.1,
        "top_p": 0.8,
        "do_sample": true,
        "repetition_penalty": 1.05,
        "top_k": 10
      }
    },

    "whisper-large-v3-turbo-arabic": {
      "model_id": "mboushaba/whisper-large-v3-turbo-arabic",
      "engine_type": "transformers",
      "quantization": null,
      "dtype": "float16",
      "name": "whisper-large-v3-turbo-arabic",
      "description": "Whisper Large V3 Turbo for Arabic audio transcription",
      "model_architecture": "whisper",
      "model_filename": null,
      "documentation": null,
      "custom_generation_params": null
    },

    "xtts-v2": {
      "model_id": "coqui/XTTS-v2",
      "engine_type": "xtts",
      "quantization": null,
      "max_new_tokens": null,
      "dtype": "float16",
      "name": "xtts-v2",
      "description": "Coqui XTTS-v2 for high-quality multilingual text-to-speech (Mock Mode - TTS library required)",
      "model_architecture": "xtts",
      "model_filename": null,
      "documentation": "https://huggingface.co/coqui/XTTS-v2",
      "custom_generation_params": {
        "emotion": "neutral",
        "speed": 1.0,
        "supported_languages": ["ar", "en", "es", "fr", "de", "it", "pt", "pl", "tr", "ru", "nl", "cs", "zh", "ja", "hu", "ko"]
      }
    },

    "edge-tts": {
      "model_id": "microsoft/edge-tts",
      "engine_type": "edge_tts",
      "quantization": null,
      "max_new_tokens": null,
      "dtype": null,
      "name": "edge-tts",
      "description": "Microsoft Edge TTS for high-quality multilingual text-to-speech (Python 3.12+ compatible)",
      "model_architecture": "edge_tts",
      "model_filename": null,
      "documentation": "https://github.com/rany2/edge-tts",
      "custom_generation_params": {
        "emotion": "neutral",
        "speed": 1.0,
        "supported_languages": ["ar", "en", "es", "fr", "de", "it", "pt", "pl", "tr", "ru", "nl", "cs", "zh", "ja", "hu", "ko"]
      }
    }
  }
}
