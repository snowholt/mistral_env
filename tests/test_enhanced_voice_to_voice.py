#!/usr/bin/env python3
"""
Enhanced Voice-to-Voice Test Script for BeautyAI Framework.

Tests the complete pipeline: Audio Input â†’ STT â†’ LLM â†’ TTS â†’ Audio Output
with Coqui TTS integration, thinking mode, and content filtering.
"""

import sys
import os
import asyncio
import logging
import tempfile
import json
from pathlib import Path

# Add the project root to the path
sys.path.insert(0, '/home/lumi/beautyai')

from beautyai_inference.services.voice_to_voice_service import VoiceToVoiceService
from beautyai_inference.services.audio_transcription_service import AudioTranscriptionService

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def test_enhanced_voice_to_voice():
    """Test enhanced voice-to-voice with Coqui TTS and all features."""
    
    print("ğŸ¤ Enhanced Voice-to-Voice Test with Coqui TTS")
    print("=" * 60)
    
    # Test configurations
    test_cases = [
        {
            "name": "Basic Arabic Conversation",
            "text": "Ù…Ø±Ø­Ø¨Ø§ØŒ ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø§Ù„ÙŠÙˆÙ…ØŸ",
            "language": "ar",
            "speaker_voice": "female",
            "thinking_mode": False,
            "content_filter": True
        },
        {
            "name": "Thinking Mode Enabled",
            "text": "Ø§Ø´Ø±Ø­ Ù„ÙŠ ÙƒÙŠÙ ÙŠØ¹Ù…Ù„ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ",
            "language": "ar", 
            "speaker_voice": "female",
            "thinking_mode": True,
            "content_filter": True
        },
        {
            "name": "Advanced Generation Parameters",
            "text": "Ø§Ø­Ùƒ Ù„ÙŠ Ù‚ØµØ© Ù‚ØµÙŠØ±Ø© Ø¹Ù† Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„",
            "language": "ar",
            "speaker_voice": "male",
            "thinking_mode": False,
            "content_filter": False,
            "generation_config": {
                "temperature": 0.7,
                "top_p": 0.9,
                "top_k": 50,
                "repetition_penalty": 1.1,
                "max_new_tokens": 200
            }
        },
        {
            "name": "English with Thinking Override",
            "text": "/think Explain quantum computing in simple terms",
            "language": "en",
            "speaker_voice": "female",
            "thinking_mode": False,  # Should be overridden by /think command
            "content_filter": True
        }
    ]
    
    # Setup output directory
    output_dir = Path("/home/lumi/beautyai/voice_tests/enhanced_voice_to_voice")
    output_dir.mkdir(parents=True, exist_ok=True)
    print(f"ğŸ“ Output directory: {output_dir}")
    
    try:
        # Initialize the Enhanced Voice-to-Voice Service
        print("\nğŸš€ Initializing Enhanced Voice-to-Voice Service...")
        v2v_service = VoiceToVoiceService(content_filter_strictness="balanced")
        
        # Initialize models with Coqui TTS
        print("ğŸ“¡ Loading models...")
        models_result = v2v_service.initialize_models(
            stt_model="whisper-large-v3-turbo-arabic",
            tts_model="coqui-tts-arabic",  # Using Coqui TTS
            chat_model="qwen3-unsloth-q4ks",
            language="ar"
        )
        
        print(f"ğŸ“Š Model initialization results: {models_result}")
        
        if not all(models_result.values()):
            print("âŒ Failed to initialize all models")
            failed_models = [k for k, v in models_result.items() if not v]
            print(f"Failed models: {failed_models}")
            return False
        
        print("âœ… All models loaded successfully!")
        
        # Test TTS Service separately first
        print("\nğŸ§ª Testing TTS Service with Coqui TTS...")
        tts_service = v2v_service.tts_service
        
        test_tts_output = output_dir / "test_coqui_tts.wav"
        tts_result = tts_service.text_to_speech(
            text="Ù‡Ø°Ø§ Ø§Ø®ØªØ¨Ø§Ø± Ù„Ù…Ø­Ø±Ùƒ ÙƒÙˆÙƒÙŠ Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ø¹Ø±Ø¨ÙŠ",
            output_path=str(test_tts_output),
            language="ar",
            speaker_voice="female"
        )
        
        if tts_result:
            print(f"âœ… Coqui TTS test successful: {test_tts_output}")
        else:
            print("âŒ Coqui TTS test failed")
            return False
        
        # Get model status
        print("\nğŸ“Š Model Status:")
        status = v2v_service.get_models_status()
        print(json.dumps(status, indent=2))
        
        # Run comprehensive tests
        print("\nğŸ§ª Running Enhanced Voice-to-Voice Tests...")
        
        for i, test_case in enumerate(test_cases, 1):
            print(f"\nğŸ¯ Test {i}: {test_case['name']}")
            print("-" * 40)
            
            # Create a temporary audio file from text (using STT in reverse for testing)
            temp_audio_path = output_dir / f"temp_input_{i}.wav"
            
            # Generate audio from text for testing input
            input_audio_result = tts_service.text_to_speech(
                text=test_case["text"],
                output_path=str(temp_audio_path),
                language=test_case["language"],
                speaker_voice=test_case.get("speaker_voice", "female")
            )
            
            if not input_audio_result:
                print(f"âŒ Failed to create test audio for test {i}")
                continue
            
            print(f"ğŸ“ Test input text: {test_case['text']}")
            print(f"ğŸµ Created test audio: {temp_audio_path}")
            
            # Read audio file as bytes for testing
            with open(temp_audio_path, "rb") as f:
                audio_bytes = f.read()
            
            # Process voice-to-voice conversation
            result = v2v_service.voice_to_voice_bytes(
                audio_bytes=audio_bytes,
                audio_format="wav",
                session_id=f"test_session_{i}",
                input_language=test_case["language"],
                output_language=test_case["language"],
                speaker_voice=test_case.get("speaker_voice", "female"),
                enable_content_filter=test_case.get("content_filter", True),
                content_filter_strictness="balanced",
                thinking_mode=test_case.get("thinking_mode", False),
                generation_config=test_case.get("generation_config", {})
            )
            
            if result["success"]:
                print(f"âœ… Voice-to-voice processing successful!")
                print(f"ğŸ“ Transcription: {result['transcription']}")
                print(f"ğŸ¤– AI Response: {result['response'][:100]}...")
                print(f"ğŸµ Audio output: {result['audio_output']}")
                print(f"â±ï¸ Processing time: {result['processing_time']:.2f}s")
                
                # Display metadata
                metadata = result.get("metadata", {})
                print(f"ğŸ§  Thinking mode: {metadata.get('thinking_mode', 'N/A')}")
                print(f"ğŸ”’ Content filter: {metadata.get('content_filter_applied', 'N/A')}")
                print(f"âš™ï¸ Generation config: {metadata.get('generation_config', {})}")
                
            else:
                print(f"âŒ Voice-to-voice processing failed: {result.get('error', 'Unknown error')}")
            
            print()
        
        # Test session management
        print("ğŸ“š Testing Session Management...")
        session_history = v2v_service.get_session_history("test_session_1")
        if session_history:
            print(f"âœ… Session history retrieved: {len(session_history)} messages")
        else:
            print("â„¹ï¸ No session history found")
        
        # Test memory stats
        print("\nğŸ’¾ Memory Statistics:")
        memory_stats = v2v_service.get_memory_stats()
        print(json.dumps(memory_stats, indent=2))
        
        print("\nğŸ‰ Enhanced Voice-to-Voice test completed successfully!")
        print(f"ğŸ“ All outputs saved to: {output_dir}")
        
        # Clean up models
        print("\nğŸ§¹ Cleaning up models...")
        v2v_service.unload_all_models()
        print("âœ… Models unloaded successfully")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ Error during enhanced voice-to-voice test: {e}")
        return False

def main():
    """Main function to run the enhanced test."""
    print("ğŸ§ª BeautyAI Enhanced Voice-to-Voice Test Suite")
    print("=" * 60)
    print("Testing complete pipeline with Coqui TTS integration:")
    print("ğŸ”„ Audio Input â†’ STT â†’ LLM â†’ TTS â†’ Audio Output")
    print("ğŸ¯ Features: Thinking mode, Content filtering, Advanced parameters")
    print("")
    
    success = asyncio.run(test_enhanced_voice_to_voice())
    
    if success:
        print("\nâœ… All tests passed! Enhanced voice-to-voice is working correctly.")
        print("\nğŸš€ Ready for production use with:")
        print("   â€¢ Coqui TTS for high-quality Arabic voice synthesis")
        print("   â€¢ Advanced thinking mode with /think and /no_think commands")
        print("   â€¢ Configurable content filtering")
        print("   â€¢ 25+ LLM generation parameters")
        print("   â€¢ Session management and conversation history")
    else:
        print("\nâŒ Some tests failed. Check the output above for issues.")
        sys.exit(1)

if __name__ == "__main__":
    main()
