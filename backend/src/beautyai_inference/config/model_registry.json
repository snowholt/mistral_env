{
  "models": {
    "qwen3-model": {
      "model_id": "Qwen/Qwen3-14B",
      "engine_type": "transformers",
      "quantization": "4bit",
      "dtype": "bfloat16",
      "max_new_tokens": 1024,
      "name": "qwen3-model",
      "description": "Qwen3 14B model (4-bit quantized) - Transformers engine",
      "model_architecture": "causal_lm",
      "custom_generation_params": {
        "temperature": 0.1,
        "top_p": 0.95,
        "do_sample": true,
        "repetition_penalty": 1.1
      }
    },
      
    "deepseek-r1-qwen-14b-multilingual": {
      "model_id": "lightblue/DeepSeek-R1-Distill-Qwen-14B-Multilingual",
      "engine_type": "transformers",
      "quantization": "4bit",
      "dtype": "bfloat16",
      "max_new_tokens": 1024,
      "name": "deepseek-r1-qwen-14b-multilingual",
      "description": "DeepSeek R1 Distill Qwen 14B Multilingual - Transformers engine",
      "model_architecture": "causal_lm",
      "custom_generation_params": {
        "temperature": 0.6,
        "top_p": 0.95,
        "do_sample": true,
        "repetition_penalty": 1.1
      }
    },

    "qwen3-official-q4km": {
      "model_id": "Qwen/Qwen3-14B-GGUF",
      "engine_type": "llama.cpp",
      "quantization": "Q4_K_M",
      "dtype": "float16",
      "model_filename": "Qwen3-14B-Q4_K_M.gguf",
      "tokenizer_model_id": "Qwen/Qwen3-14B",
      "max_new_tokens": 256,
      "name": "qwen3-official-q4km",
      "description": "Qwen3 14B Q4_K_M - Official GGUF (8.4GB) - LlamaCpp engine",
      "model_architecture": "causal_lm",
      "custom_generation_params": {
        "temperature": 0.1,
        "top_p": 0.8,
        "do_sample": true,
        "repetition_penalty": 1.05,
        "top_k": 10
      }
    },

    "qwen3-official-q6k": {
      "model_id": "Qwen/Qwen3-14B-GGUF",
      "engine_type": "llama.cpp",
      "quantization": "Q6_K",
      "dtype": "float16",
      "model_filename": "Qwen3-14B-Q6_K.gguf",
      "tokenizer_model_id": "Qwen/Qwen3-14B",
      "max_new_tokens": 256,
      "name": "qwen3-official-q6k",
      "description": "Qwen3 14B Q6_K - Official GGUF high quality (12GB) - LlamaCpp engine",
      "model_architecture": "causal_lm",
      "custom_generation_params": {
        "temperature": 0.1,
        "top_p": 0.8,
        "do_sample": true,
        "repetition_penalty": 1.05,
        "top_k": 10
      }
    },

    "qwen3-unsloth-q4ks": {
      "model_id": "unsloth/Qwen3-14B-GGUF",
      "engine_type": "llama.cpp",
      "quantization": "Q4_K_S",
      "dtype": "float16",
      "model_filename": "Qwen3-14B-Q4_K_S.gguf",
      "tokenizer_model_id": "Qwen/Qwen3-14B",
      "max_new_tokens": 256,
      "name": "qwen3-unsloth-q4ks",
      "description": "Qwen3 14B Q4_K_S - Unsloth optimized fastest (8.0GB) - LlamaCpp engine",
      "model_architecture": "causal_lm",
      "n_gpu_layers": -1,
      "n_ctx": 4096,
      "n_batch": 8192,
      "n_threads": 24,
      "custom_generation_params": {
        "temperature": 0.1,
        "top_p": 0.8,
        "do_sample": true,
        "repetition_penalty": 1.05,
        "top_k": 10
      }
    },

    "qwen3-unsloth-q4km": {
      "model_id": "unsloth/Qwen3-14B-GGUF",
      "engine_type": "llama.cpp",
      "quantization": "Q4_K_M",
      "dtype": "float16",
      "model_filename": "Qwen3-14B-Q4_K_M.gguf",
      "tokenizer_model_id": "Qwen/Qwen3-14B",
      "max_new_tokens": 256,
      "name": "qwen3-unsloth-q4km",
      "description": "Qwen3 14B Q4_K_M - Unsloth optimized balanced (8.4GB) - LlamaCpp engine",
      "model_architecture": "causal_lm",
      "custom_generation_params": {
        "temperature": 0.1,
        "top_p": 0.8,
        "do_sample": true,
        "repetition_penalty": 1.05,
        "top_k": 10
      }
    },

    "qwen3-unsloth-q6k": {
      "model_id": "unsloth/Qwen3-14B-GGUF",
      "engine_type": "llama.cpp",
      "quantization": "Q6_K",
      "dtype": "float16",
      "model_filename": "Qwen3-14B-Q6_K.gguf",
      "tokenizer_model_id": "Qwen/Qwen3-14B",
      "max_new_tokens": 256,
      "name": "qwen3-unsloth-q6k",
      "description": "Qwen3 14B Q6_K - Unsloth optimized high quality (12GB) - LlamaCpp engine",
      "model_architecture": "causal_lm",
      "custom_generation_params": {
        "temperature": 0.1,
        "top_p": 0.8,
        "do_sample": true,
        "repetition_penalty": 1.05,
        "top_k": 10
      }
    },

    "bee1reason-arabic-q4ks": {
      "model_id": "mradermacher/Bee1reason-arabic-Qwen-14B-i1-GGUF",
      "engine_type": "llama.cpp",
      "quantization": "i1-Q4_K_S",
      "dtype": "float16",
      "max_new_tokens": 256,
      "name": "bee1reason-arabic-q4ks",
      "description": "Bee1reason Arabic Qwen 14B i1-Q4_K_S - Fast Arabic reasoning - LlamaCpp engine (cleaned)",
      "model_architecture": "causal_lm",
      "model_filename": "Bee1reason-arabic-Qwen-14B.i1-Q4_K_S.gguf",
      "blob_id": "334c5a6e68b4b18828cc3aeb771a22bd9bcbbca6d55c29ce507f3967c7db1af5",
      "custom_generation_params": {
        "temperature": 0.1,
        "top_p": 0.8,
        "do_sample": true,
        "repetition_penalty": 1.05,
        "top_k": 10
      }
    },

    "bee1reason-arabic-q4km-i1": {
      "model_id": "mradermacher/Bee1reason-arabic-Qwen-14B-i1-GGUF",
      "engine_type": "llama.cpp",
      "quantization": "i1-Q4_K_M",
      "dtype": "float16",
      "max_new_tokens": 256,
      "name": "bee1reason-arabic-q4km-i1",
      "description": "Bee1reason Arabic Qwen 14B i1-Q4_K_M - Balanced Arabic reasoning - LlamaCpp engine (cleaned)",
      "model_architecture": "causal_lm",
      "model_filename": "Bee1reason-arabic-Qwen-14B.i1-Q4_K_M.gguf",
      "blob_id": "b17a5d0aa671fe8fad0abdc9c9914386f9a5b73bc69366500ed8f99b371a4552",
      "custom_generation_params": {
        "temperature": 0.1,
        "top_p": 0.8,
        "do_sample": true,
        "repetition_penalty": 1.05,
        "top_k": 10
      }
    },

    "whisper-turbo-arabic": {
      "model_id": "large-v3-turbo",
      "engine_type": "faster_whisper",
      "quantization": "float16",
      "dtype": "float16",
      "name": "whisper-turbo-arabic",
      "description": "GPU-OPTIMIZED: Latest Whisper Large-v3-Turbo with RTX 4090 acceleration (809MB, 4x faster than turbo)",
      "model_architecture": "whisper",
      "model_filename": null,
      "documentation": "https://huggingface.co/openai/whisper-large-v3-turbo",
      "custom_generation_params": {
        "beam_size": 1,
        "batch_size": 16,
        "temperature": 0.0,
        "condition_on_previous_text": false,
        "vad_filter": true,
        "vad_parameters": {
          "min_silence_duration_ms": 250,
          "speech_pad_ms": 30
        },
        "optimization_level": "gpu_speed",
        "target_latency_ms": 500,
        "gpu_acceleration": true,
        "flash_attention": true
      }
    },

    "edge-tts": {
      "model_id": "microsoft/edge-tts",
      "engine_type": "edge_tts",
      "quantization": null,
      "max_new_tokens": null,
      "dtype": null,
      "name": "edge-tts",
      "description": "Primary TTS: Microsoft Edge TTS for high-quality multilingual text-to-speech",
      "model_architecture": "edge_tts",
      "model_filename": null,
      "documentation": "https://github.com/rany2/edge-tts",
      "custom_generation_params": {
        "emotion": "neutral",
        "speed": 1.0,
        "supported_languages": ["ar", "en", "es", "fr", "de", "it", "pt", "pl", "tr", "ru", "nl", "cs", "zh", "ja", "hu", "ko"]
      }
    }
  }
}
