
{
  "default_model": "qwen3-model",
  "models": {
    "qwen3-model": {
      "model_id": "Qwen/Qwen3-14B",
      "engine_type": "transformers",
      "quantization": "4bit",
      "dtype": "bfloat16",
      "max_new_tokens": 1024,
      "name": "qwen3-model",
      "description": "Qwen3 14B model (4-bit quantized)",
      "model_architecture": "causal_lm",
      "custom_generation_params": {
        "temperature": 0.1,
        "top_p": 0.95,
        "do_sample": true,
        "repetition_penalty": 1.1
      }
    },
      
    "deepseek-r1-qwen-14b-multilingual": {
      "model_id": "lightblue/DeepSeek-R1-Distill-Qwen-14B-Multilingual",
      "engine_type": "transformers",
      "quantization": "4bit",
      "dtype": "bfloat16",
      "max_new_tokens": 1024,
      "name": "deepseek-r1-qwen-14b-multilingual",
      "description": "DeepSeek R1 Distill Qwen 14B Multilingual model",
      "model_architecture": "causal_lm",
      "custom_generation_params": {
        "temperature": 0.6,
        "top_p": 0.95,
        "do_sample": true,
        "repetition_penalty": 1.1
      }
    },

      "mistral-devstral-small-2505-gguf": {
      "model_id": "mistralai/Devstral-Small-2505_gguf",
      "engine_type": "llama.cpp",
      "quantization": "Q4_K_M",
      "dtype": "float16",
      "max_new_tokens": 512,
      "name": "mistral-devstral-small-2505-gguf",
      "description": "Mistral Devstral Small 2505 (GGUF Q4_K_M format - ~14GB VRAM)",
      "model_architecture": "causal_lm",
      "model_filename": "devstralQ4_K_M.gguf",
      "custom_generation_params": {
        "temperature": 0.1,
        "top_p": 0.8,
        "do_sample": true,
        "repetition_penalty": 1.05,
        "top_k": 10
      }
    },
    "bee1reason-arabic-qwen-14b-q4km-gguf": {
      "model_id": "beetleware/Bee1reason-arabic-Qwen-14B-Q4_K_M-GGUF",
      "engine_type": "llama.cpp",
      "quantization": "Q4_K_M",
      "dtype": "float16",
      "max_new_tokens": 128,
      "name": "bee1reason-arabic-qwen-14b-q4km-gguf",
      "description": "Bee1reason Arabic Qwen 14B model (GGUF Q4_K_M format - ~8GB VRAM)",
      "model_architecture": "causal_lm",
      "model_filename": "Bee1reason-arabic-Qwen-14B-Q4_K_M.gguf",
      "custom_generation_params": {
        "temperature": 0.0,
        "top_p": 0.5,
        "do_sample": true,
        "repetition_penalty": 1.02,
        "top_k": 1
      }
    },
    "bee1reason-arabic-qwen-14b-i1q4ks-gguf": {
      "model_id": "mradermacher/Bee1reason-arabic-Qwen-14B-i1-GGUF",
      "engine_type": "llama.cpp",
      "quantization": "i1-Q4_K_S",
      "dtype": "float16",
      "max_new_tokens": 64,
      "name": "bee1reason-arabic-qwen-14b-i1q4ks-gguf",
      "description": "Bee1reason Arabic Qwen 14B model (GGUF i1-Q4_K_S format - ~7.5GB VRAM)",
      "model_architecture": "causal_lm",
      "model_filename": "Bee1reason-arabic-Qwen-14B.i1-Q4_K_S.gguf",
      "custom_generation_params": {
        "temperature": 0.01,
        "top_p": 0.5,
        "do_sample": true,
        "repetition_penalty": 1.0,
        "top_k": 1
      }
    },
    "qwen3-14b-gguf": {
      "model_id": "Qwen/Qwen3-14B-GGUF",
      "engine_type": "llama.cpp",
      "quantization": "Q4_K_M",
      "dtype": "float16",
      "max_new_tokens": 128,
      "name": "qwen3-14b-gguf",
      "description": "Qwen3 14B model (GGUF Q4_K_M format - optimized for speed)",
      "model_architecture": "causal_lm",
      "custom_generation_params": {
        "temperature": 0.1,
        "top_p": 0.8,
        "do_sample": true,
        "repetition_penalty": 1.05,
        "top_k": 10
      }
    }
  }
}
