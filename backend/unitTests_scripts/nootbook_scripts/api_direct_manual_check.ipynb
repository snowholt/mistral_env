{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b0ba304",
   "metadata": {},
   "source": [
    "# API vs Direct Chat Manual Inspection Notebook\n",
    "This notebook provides two helper functions:\n",
    "1. **api_chat** - calls the running BeautyAI REST API.\n",
    "2. **direct_chat** - invokes the internal ChatService directly.\n",
    "\n",
    "You can: \n",
    "- Ask the *same* question with identical parameters.\n",
    "- Inspect whether responses match.\n",
    "- Compare output structure / format.\n",
    "- Check whether the same ChatService instance ID persists (printed).\n",
    "\n",
    "No regex cleaning, no auto comparison; just raw outputs for your manual review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4da6e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions ready: api_chat, direct_chat\n"
     ]
    }
   ],
   "source": [
    "import sys, json, logging, requests\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict\n",
    "\n",
    "# Silence noisy loggers\n",
    "logging.basicConfig(level=logging.CRITICAL)\n",
    "for noisy in [\"uvicorn\", \"uvicorn.error\", \"uvicorn.access\", \"httpx\", \"transformers\", \"torch\"]:\n",
    "    logging.getLogger(noisy).setLevel(logging.CRITICAL)\n",
    "\n",
    "# Add backend source\n",
    "backend_src = Path('..').resolve().parent / 'src'\n",
    "sys.path.insert(0, str(backend_src))\n",
    "\n",
    "from beautyai_inference.services.inference.chat_service import ChatService  # type: ignore\n",
    "from beautyai_inference.config.config_manager import AppConfig  # type: ignore\n",
    "from beautyai_inference.services.model.registry_service import ModelRegistryService  # type: ignore\n",
    "\n",
    "API_BASE_URL = 'http://127.0.0.1:8000'\n",
    "_CHAT_SERVICE = ChatService()\n",
    "_APP_CONFIG = AppConfig()\n",
    "_MODEL_REGISTRY_SERVICE = ModelRegistryService()\n",
    "\n",
    "def api_chat(model_name: str, message: str, **params) -> Dict[str, Any]:\n",
    "    payload = {'model_name': model_name, 'message': message} | params\n",
    "    r = requests.post(f'{API_BASE_URL}/inference/chat', json=payload, timeout=60)\n",
    "    try: return r.json()\n",
    "    except Exception: return {'error': True, 'status_code': r.status_code, 'text': r.text} \n",
    "\n",
    "def direct_chat(model_name: str, message: str, **params) -> Dict[str, Any]:\n",
    "    if not getattr(_APP_CONFIG, 'model_registry', None): _APP_CONFIG.load_model_registry()\n",
    "    model_cfg = _MODEL_REGISTRY_SERVICE.get_model(_APP_CONFIG, model_name)\n",
    "    if model_cfg is None: return {'error': f'model {model_name} not in registry'}\n",
    "    gen_cfg = params.copy()\n",
    "    for k in ['disable_content_filter','enable_thinking']: gen_cfg.pop(k, None)\n",
    "    response, detected_language, _, session_id = _CHAT_SERVICE.chat(\n",
    "        message=message, model_name=model_name, model_config=model_cfg,\n",
    "        generation_config=gen_cfg, conversation_history=[], response_language='auto',\n",
    "        session_id=None, disable_content_filter=params.get('disable_content_filter', False)\n",
    "    )\n",
    "    return {\n",
    "        'final_content': response,\n",
    "        'detected_language': detected_language,\n",
    "        'session_id': session_id,\n",
    "        'chat_service_id': id(_CHAT_SERVICE),\n",
    "        'model_name': model_name,\n",
    "    }\n",
    "print('Functions ready: api_chat, direct_chat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e52ac74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== API RESULT RAW JSON ===\n",
      "{\n",
      "  \"success\": true,\n",
      "  \"data\": null,\n",
      "  \"timestamp\": \"2025-08-22T02:24:52.188558Z\",\n",
      "  \"execution_time_ms\": 127.55966186523438,\n",
      "  \"response\": \"…\",\n",
      "  \"session_id\": \"default\",\n",
      "  \"model_name\": \"qwen3-unsloth-q4ks\",\n",
      "  \"generation_stats\": {\n",
      "    \"model_info\": {},\n",
      "    \"generation_config_used\": {\n",
      "      \"temperature\": 0.0,\n",
      "      \"top_p\": 0.95,\n",
      "      \"top_k\": 20,\n",
      "      \"repetition_penalty\": 1.05,\n",
      "      \"max_new_tokens\": 200,\n",
      "      \"do_sample\": false,\n",
      "      \"enable_thinking\": false\n",
      "    },\n",
      "    \"content_filter_config\": {\n",
      "      \"strictness_level\": \"disabled\"\n",
      "    },\n",
      "    \"performance\": {\n",
      "      \"total_time_ms\": 127.55966186523438,\n",
      "      \"generation_time_ms\": 125.53858757019043,\n",
      "      \"tokens_generated\": 1,\n",
      "      \"tokens_per_second\": 7.96567827753268,\n",
      "      \"thinking_tokens\": 0\n",
      "    }\n",
      "  },\n",
      "  \"effective_config\": {\n",
      "    \"temperature\": 0.0,\n",
      "    \"top_p\": 0.95,\n",
      "    \"top_k\": 20,\n",
      "    \"repetition_penalty\": 1.05,\n",
      "    \"max_new_tokens\": 200,\n",
      "    \"do_sample\": false,\n",
      "    \"enable_thinking\": false\n",
      "  },\n",
      "  \"preset_used\": null,\n",
      "  \"thinking_enabled\": false,\n",
      "  \"content_filter_applied\": false,\n",
      "  \"content_filter_strictness\": \"disabled\",\n",
      "  \"content_filter_bypassed\": true,\n",
      "  \"tokens_generated\": 1,\n",
      "  \"generation_time_ms\": 125.53858757019043,\n",
      "  \"tokens_per_second\": 7.97,\n",
      "  \"thinking_content\": null,\n",
      "  \"final_content\": \"…\",\n",
      "  \"error\": null\n",
      "}\n",
      "=== DIRECT RESULT RAW JSON ===\n",
      "{\n",
      "  \"error\": \"model qwen3-unsloth-q4ks not in registry\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Example usage — adjust model, message, and params as needed.\n",
    "model_name = 'qwen3-unsloth-q4ks'  # change if needed\n",
    "message = '/no_think What is botox?'\n",
    "params = {\n",
    "    'temperature': 0.0,\n",
    "    'top_p': 0.95,\n",
    "    'max_new_tokens': 200,\n",
    "    'do_sample': False,\n",
    "    'disable_content_filter': True,\n",
    "    'enable_thinking': False,\n",
    "} \n",
    "\n",
    "api_result = api_chat(model_name, message, **params)\n",
    "direct_result = direct_chat(model_name, message, **params)\n",
    "print('=== API RESULT RAW JSON ===')\n",
    "print(json.dumps(api_result, ensure_ascii=False, indent=2))\n",
    "print('=== DIRECT RESULT RAW JSON ===')\n",
    "print(json.dumps(direct_result, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab907128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing API with Arabic question...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "Response: <think>\n",
      "Okay, the user is asking about the main benefit of Intense Pulsed Light (IPL) treatment. Let me recall what IPL is used for. It's a non-invasive procedure that uses broad-spectrum light to target various skin issues.\n",
      "First, I should mention the primary uses: things like sun damage, age spots, freckles, and uneven skin tone. Also, it can help with vascular issues like spider veins and rosacea. Maybe also mention hair removal as another application.\n",
      "But the user specifically asked for the \n",
      "Language: No language field\n"
     ]
    }
   ],
   "source": [
    "# Simple test to debug the model response generation\n",
    "import requests\n",
    "\n",
    "# Test just the API with a simple question\n",
    "test_payload = {\n",
    "    \"model_name\": \"qwen3-unsloth-q4ks\",\n",
    "    \"message\": \"ما هي الفائدة الرئيسية لعلاج الضوء النبدي المكثف؟\",\n",
    "    \"temperature\": 0.7,\n",
    "    \"max_new_tokens\": 150,\n",
    "    \"disable_content_filter\": True,\n",
    "}\n",
    "\n",
    "print(\"Testing API with Arabic question...\")\n",
    "response = requests.post('http://127.0.0.1:8000/inference/chat', json=test_payload, timeout=60)\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    print(f\"Response: {result.get('response', 'No response field')[:500]}\")\n",
    "    print(f\"Language: {result.get('language', 'No language field')}\")\n",
    "else:\n",
    "    print(f\"Error: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acc52c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with /no_think instruction...\n",
      "Status Code: 200\n",
      "Response: <think>\n",
      "Okay, the user is asking about the main benefit of Intense Pulsed Light (IPL) treatment. Let me recall what IPL is used for. It's a non-invasive procedure that uses broad-spectrum light to target various skin issues.\n",
      "First, I should mention the primary uses: things like sun damage, pigmentation, and vascular lesions. The main benefit here is improving skin texture and appearance by reducing these issues. Also, IPL can help with hair removal, but the user might be more interested in skin rejuvenation.\n",
      "I need to make sure the answer is clear and concise, in Arabic only. Avoid medical jargon so it's easy for patients to understand. Highlight the key points: treating pigmentation, sunspots\n",
      "Language: No language field\n",
      "Response Length: 702\n"
     ]
    }
   ],
   "source": [
    "# Test the /no_think instruction specifically\n",
    "test_payload_no_think = {\n",
    "    \"model_name\": \"qwen3-unsloth-q4ks\",\n",
    "    \"message\": \"ما هي الفائدة الرئيسية لعلاج الضوء النبدي المكثف؟ /no_think\",\n",
    "    \"temperature\": 0.7,\n",
    "    \"max_new_tokens\": 150,\n",
    "    \"disable_content_filter\": True,\n",
    "}\n",
    "\n",
    "print(\"Testing with /no_think instruction...\")\n",
    "response = requests.post('http://127.0.0.1:8000/inference/chat', json=test_payload_no_think, timeout=60)\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    print(f\"Response: {result.get('response', 'No response field')}\")\n",
    "    print(f\"Language: {result.get('language', 'No language field')}\")\n",
    "    print(f\"Response Length: {len(result.get('response', ''))}\")\n",
    "else:\n",
    "    print(f\"Error: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7ddf59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with enable_thinking=False...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "Response: العلاج بالضوء النبدي المكثف (IPL) يُستخدم بشكل رئيسي لتحسين مظهر البشرة من خلال تقليل البقع الداكنة، التصبغات، والتهابات البشرة. كما يساعد في تقليل ظهور الشعر الزائد وتحسين نضارة البشرة.\n",
      "Language: No language field\n",
      "Response Length: 186\n",
      "Thinking Enabled: False\n"
     ]
    }
   ],
   "source": [
    "# Test the fixed API with enable_thinking=False explicitly\n",
    "test_payload_fixed = {\n",
    "    \"model_name\": \"qwen3-unsloth-q4ks\",\n",
    "    \"message\": \"ما هي الفائدة الرئيسية لعلاج الضوء النبدي المكثف؟\",\n",
    "    \"temperature\": 0.3,\n",
    "    \"top_p\": 0.95,\n",
    "    \"max_new_tokens\": 150,\n",
    "    \"disable_content_filter\": True,\n",
    "    \"enable_thinking\": False,  # Explicitly disable thinking mode\n",
    "}\n",
    "\n",
    "print(\"Testing with enable_thinking=False...\")\n",
    "response = requests.post('http://127.0.0.1:8000/inference/chat', json=test_payload_fixed, timeout=60)\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    print(f\"Response: {result.get('response', 'No response field')}\")\n",
    "    print(f\"Language: {result.get('language', 'No language field')}\")\n",
    "    print(f\"Response Length: {len(result.get('response', ''))}\")\n",
    "    print(f\"Thinking Enabled: {result.get('thinking_enabled', 'N/A')}\")\n",
    "else:\n",
    "    print(f\"Error: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4948b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking recent API logs for enable_thinking debug messages...\n"
     ]
    }
   ],
   "source": [
    "# Check recent API logs for debug messages about enable_thinking\n",
    "import subprocess\n",
    "\n",
    "print(\"Checking recent API logs for enable_thinking debug messages...\")\n",
    "try:\n",
    "    result = subprocess.run([\n",
    "        \"sudo\", \"journalctl\", \"-u\", \"beautyai-api.service\", \n",
    "        \"--since\", \"2 minutes ago\", \"--no-pager\"\n",
    "    ], capture_output=True, text=True, timeout=10)\n",
    "    \n",
    "    lines = result.stdout.split('\\n')\n",
    "    relevant_lines = [line for line in lines if any(keyword in line.lower() for keyword in [\n",
    "        'enable_thinking', 'chat template', 'fallback', 'debug'\n",
    "    ])]\n",
    "    \n",
    "    for line in relevant_lines[-10:]:  # Show last 10 relevant lines\n",
    "        print(line)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error checking logs: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23a89d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test remote API availability and streaming voice status\n",
    "import requests\n",
    "import ssl\n",
    "import urllib3\n",
    "\n",
    "# Disable SSL warnings for self-signed certificates\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "def test_remote_api():\n",
    "    base_url = \"https://api.gmai.sa\"\n",
    "    \n",
    "    # Test basic API health\n",
    "    try:\n",
    "        response = requests.get(f\"{base_url}/health\", verify=False, timeout=10)\n",
    "        print(f\"API Health Status: {response.status_code}\")\n",
    "        if response.status_code == 200:\n",
    "            print(f\"API Health Response: {response.json()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"API Health Check Failed: {e}\")\n",
    "    \n",
    "    # Test streaming voice status endpoint\n",
    "    try:\n",
    "        response = requests.get(f\"{base_url}/api/v1/ws/streaming-voice/status\", verify=False, timeout=10)\n",
    "        print(f\"Streaming Voice Status: {response.status_code}\")\n",
    "        if response.status_code == 200:\n",
    "            print(f\"Streaming Voice Response: {response.json()}\")\n",
    "        else:\n",
    "            print(f\"Error Response: {response.text}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Streaming Voice Status Check Failed: {e}\")\n",
    "        \n",
    "    # Test basic inference endpoint\n",
    "    try:\n",
    "        test_payload = {\n",
    "            \"model_name\": \"qwen3-unsloth-q4ks\",\n",
    "            \"message\": \"Hello test\",\n",
    "            \"disable_content_filter\": True,\n",
    "            \"max_new_tokens\": 10\n",
    "        }\n",
    "        response = requests.post(f\"{base_url}/inference/chat\", json=test_payload, verify=False, timeout=30)\n",
    "        print(f\"Inference Test Status: {response.status_code}\")\n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            print(f\"Inference Test Success - Response length: {len(result.get('response', ''))}\")\n",
    "        else:\n",
    "            print(f\"Inference Error: {response.text[:200]}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Inference Test Failed: {e}\")\n",
    "\n",
    "test_remote_api()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
