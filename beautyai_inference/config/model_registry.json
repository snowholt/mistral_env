{
  "default_model": "qwen3-model",
  "models": {
    "qwen3-model": {
      "model_id": "Qwen/Qwen3-14B",
      "engine_type": "transformers",
      "quantization": "4bit",
      "dtype": "bfloat16",
      "max_new_tokens": 1024,
      "name": "qwen3-model",
      "description": "Qwen3 14B model (4-bit quantized)",
      "model_architecture": "causal_lm",
      "custom_generation_params": {
        "temperature": 0.1,
        "top_p": 0.95,
        "do_sample": true,
        "repetition_penalty": 1.1
      }
    },
    "bee1reason-arabic-qwen-14b": {
      "model_id": "beetlware/Bee1reason-arabic-Qwen-14B",
      "engine_type": "transformers",
      "quantization": "none",
      "dtype": "float16",
      "max_new_tokens": 1024,
      "name": "bee1reason-arabic-qwen-14b",
      "description": "Arabic-optimized Qwen 14B model (float16)",
      "model_architecture": "causal_lm",
      
      "custom_generation_params": {
        "temperature": 0.6,
        "top_p": 0.95,
        "do_sample": true,
        "repetition_penalty": 1.1
      }
    },
    "bee1reason-arabic-qwen-14b-gguf": {
      "model_id": "beetlware/Bee1reason-arabic-Qwen-14B-Q4_K_M-GGUF",
      "engine_type": "llama.cpp",
      "quantization": "Q4_K_M",
      "dtype": "float16",
      "max_new_tokens": 1024,
      "name": "bee1reason-arabic-qwen-14b-gguf",
      "description": "Arabic-optimized Qwen 14B model (GGUF Q4_K_M format)",
      "model_architecture": "causal_lm",
      
      "custom_generation_params": {
        "temperature": 0.6,
        "top_p": 0.95,
        "repetition_penalty": 1.1
      }
    },
    "llama-4-maverick-17b": {
      "model_id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct",
      "engine_type": "transformers",
      "quantization": "4bit",
      "dtype": "bfloat16",
      "max_new_tokens": 1024,
      "name": "llama-4-maverick-17b",
      "description": "Meta Llama-4 Maverick 17B Instruct model",
      "model_architecture": "causal_lm",
      
      "custom_generation_params": {
        "temperature": 0.6,
        "top_p": 0.9,
        "do_sample": true,
        "repetition_penalty": 1.1
      }
    },
    "deepseek-r1-qwen-14b-multilingual": {
      "model_id": "lightblue/DeepSeek-R1-Distill-Qwen-14B-Multilingual",
      "engine_type": "transformers",
      "quantization": "4bit",
      "dtype": "bfloat16",
      "max_new_tokens": 1024,
      "name": "deepseek-r1-qwen-14b-multilingual",
      "description": "DeepSeek R1 Distill Qwen 14B Multilingual model",
      "model_architecture": "causal_lm",
      
      "custom_generation_params": {
        "temperature": 0.6,
        "top_p": 0.95,
        "do_sample": true,
        "repetition_penalty": 1.1
      }
    },
    "arabic-deepseek-r1-distill-8b": {
      "model_id": "Omartificial-Intelligence-Space/Arabic-DeepSeek-R1-Distill-8B",
      "engine_type": "transformers",
      "quantization": "4bit",
      "dtype": "bfloat16",
      "max_new_tokens": 1024,
      "name": "arabic-deepseek-r1-distill-8b",
      "description": "Arabic-optimized DeepSeek R1 Distill 8B model for reasoning",
      "model_architecture": "causal_lm",
      
      "custom_generation_params": {
        "temperature": 0.5,
        "top_p": 0.9,
        "do_sample": true,
        "repetition_penalty": 1.15
      }
    },
    "deepseek-r1-qwen-14b-multilingual-gguf": {
      "model_id": "pelican7/DeepSeek-R1-Distill-Qwen-14B-Multilingual-Q4_K_M-GGUF",
      "engine_type": "llama.cpp",
      "quantization": "Q4_K_M",
      "dtype": "float16",
      "max_new_tokens": 1024,
      "name": "deepseek-r1-qwen-14b-multilingual-gguf",
      "description": "DeepSeek R1 Distill Qwen 14B Multilingual model (GGUF Q4_K_M format)",
      "model_architecture": "causal_lm",
      
      "custom_generation_params": {
        "temperature": 0.6,
        "top_p": 0.95,
        "repetition_penalty": 1.1
      }
    },

    "arabic-deepseek-r1-distill-llama3-8b": {
      "model_id": "Paula139/DeepSeek-R1-destill-llama3-8b-arabic-fine-tuned",
      "engine_type": "transformers",
      "quantization": "4bit",
      "dtype": "bfloat16",
      "max_new_tokens": 1024,
      "name": "arabic-deepseek-r1-distill-llama3-8b",
      "description": "Arabic fine-tuned DeepSeek R1 Distill Llama3 8B model for reasoning",
      "model_architecture": "causal_lm",
      
      "custom_generation_params": {
        "temperature": 0.5,
        "top_p": 0.9,
        "do_sample": true,
        "repetition_penalty": 1.15
      }
    },
    "arabic-morph-deepseek-r1-distill-llama-8b": {
      "model_id": "omarxadel/Arabic-Morph-DeepSeek-R1-Distill-Llama-8B",
      "engine_type": "transformers",
      "quantization": "4bit",
      "dtype": "bfloat16",
      "max_new_tokens": 512,
      "name": "arabic-morph-deepseek-r1-distill-llama-8b",
      "description": "Arabic Morphological DeepSeek R1 Distill Llama 8B model",
      "model_architecture": "causal_lm",
      
      "custom_generation_params": {
        "temperature": 0.3,
        "top_p": 0.9,
        "do_sample": true,
        "repetition_penalty": 1.1
      }
    }
  }
}