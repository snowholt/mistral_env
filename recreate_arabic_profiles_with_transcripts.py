#!/usr/bin/env python3
"""
Recreate Arabic Speaker Profiles with Correct Transcriptions.
This script properly creates speaker profiles using the actual transcriptions
from the provided Arabic audio files.
"""

import sys
import os
import time
import logging
from pathlib import Path
from typing import Optional

# Add the beautyai_inference package to the path
sys.path.insert(0, '/home/lumi/beautyai')

# Import torch for CUDA detection
try:
    import torch
except ImportError:
    torch = None

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def clean_old_profiles():
    """Remove old speaker profiles to start fresh."""
    profiles_dir = Path("/home/lumi/beautyai/voice_tests/arabic_speaker_profiles")
    
    if profiles_dir.exists():
        logger.info("ğŸ§¹ Cleaning old speaker profiles...")
        for profile_file in profiles_dir.glob("*.json"):
            profile_file.unlink()
            logger.info(f"   âŒ Removed: {profile_file.name}")
    
    profiles_dir.mkdir(parents=True, exist_ok=True)
    logger.info("âœ… Profile directory prepared")

def create_arabic_speaker_with_transcript(
    audio_path: str, 
    transcript: str, 
    speaker_name: str,
    gender: str
) -> Optional[str]:
    """Create Arabic speaker profile with correct transcription."""
    
    logger.info(f"ğŸ­ Creating {gender} Arabic speaker: {speaker_name}")
    logger.info(f"ğŸ“ Audio: {audio_path}")
    logger.info(f"ğŸ“ Transcript: {transcript[:50]}...")
    
    try:
        # Import OuteTTS
        import outetts
        
        # Initialize OuteTTS interface
        logger.info("ğŸ“¥ Initializing OuteTTS interface...")
        interface = outetts.Interface(
            config=outetts.ModelConfig.auto_config(
                model=outetts.Models.VERSION_1_0_SIZE_1B,
                backend=outetts.Backend.LLAMACPP,
                quantization=outetts.LlamaCppQuantization.FP16
            )
        )
        
        # Verify audio file exists
        if not os.path.exists(audio_path):
            raise FileNotFoundError(f"Audio file not found: {audio_path}")
        
        # Create output directory
        profiles_dir = Path("/home/lumi/beautyai/voice_tests/arabic_speaker_profiles")
        profiles_dir.mkdir(parents=True, exist_ok=True)
        
        # Create speaker profile path
        speaker_profile_path = profiles_dir / f"{speaker_name}.json"
        
        logger.info("ğŸ¤ Creating speaker profile with provided transcript...")
        logger.info("â±ï¸  This may take a few minutes...")
        
        # Create speaker using the correct transcript
        speaker = interface.create_speaker(
            audio_path=audio_path,
            transcript=transcript,
            whisper_model="turbo",  # Use Whisper for transcription verification
            whisper_device="cuda" if torch.cuda.is_available() else "cpu"
        )
        
        # Save the speaker profile
        interface.save_speaker(speaker, str(speaker_profile_path))
        
        logger.info(f"âœ… Speaker profile created: {speaker_profile_path}")
        
        # Test the profile with a sample from the original transcript
        test_sample = transcript.split()[:10]  # First 10 words
        test_text = " ".join(test_sample)
        
        logger.info(f"ğŸ”Š Testing speaker with original content: '{test_text}'")
        
        # Generate test audio
        test_output = interface.generate(
            config=outetts.GenerationConfig(
                text=test_text,
                generation_type=outetts.GenerationType.CHUNKED,
                speaker=speaker,
                sampler_config=outetts.SamplerConfig(
                    temperature=0.4,
                    top_p=0.9,
                    top_k=50
                ),
            )
        )
        
        # Save test output
        test_dir = Path("/home/lumi/beautyai/voice_tests/arabic_speaker_tests")
        test_dir.mkdir(parents=True, exist_ok=True)
        
        test_file = test_dir / f"transcript_test_{gender}_{speaker_name}.wav"
        test_output.save(str(test_file))
        
        logger.info(f"âœ… Test audio saved: {test_file}")
        
        return str(speaker_profile_path)
        
    except ImportError:
        logger.error("âŒ OuteTTS not available. Install with: pip install outetts")
        return None
    except Exception as e:
        logger.error(f"âŒ Failed to create {gender} speaker profile: {e}")
        return None

def test_beauty_clinic_scenarios(female_profile: str, male_profile: str):
    """Test both profiles with beauty clinic scenarios."""
    
    logger.info("ğŸ¥ Testing beauty clinic scenarios...")
    
    # Beauty clinic scenarios
    beauty_scenarios = {
        "female_greeting": "Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ ÙÙŠ Ø¹ÙŠØ§Ø¯Ø© Ø§Ù„Ø¬Ù…Ø§Ù„. ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø§Ù„ÙŠÙˆÙ…ØŸ",
        "female_services": "Ù„Ø¯ÙŠÙ†Ø§ Ø¹Ù„Ø§Ø¬Ø§Øª Ù…ØªÙ†ÙˆØ¹Ø© Ù„Ù„ÙˆØ¬Ù‡ ÙˆØ§Ù„Ø¨Ø´Ø±Ø© ÙˆØ­Ù‚Ù† Ø§Ù„Ø¨ÙˆØªÙˆÙƒØ³.",
        "male_greeting": "Ø£Ù‡Ù„Ø§Ù‹ ÙˆØ³Ù‡Ù„Ø§Ù‹ØŒ Ø£Ù†Ø§ Ø§Ù„Ø¯ÙƒØªÙˆØ± Ø£Ø­Ù…Ø¯. Ø³Ø£Ø³Ø§Ø¹Ø¯Ùƒ ÙÙŠ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø¹Ù„Ø§Ø¬ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨.",
        "male_consultation": "ÙŠÙ…ÙƒÙ†Ù†Ø§ Ù…Ù†Ø§Ù‚Ø´Ø© Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„Ø¹Ù„Ø§Ø¬ Ø§Ù„Ù…Ø®ØªÙ„ÙØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ø­ØªÙŠØ§Ø¬Ø§ØªÙƒ."
    }
    
    try:
        import outetts
        
        interface = outetts.Interface(
            config=outetts.ModelConfig.auto_config(
                model=outetts.Models.VERSION_1_0_SIZE_1B,
                backend=outetts.Backend.LLAMACPP,
                quantization=outetts.LlamaCppQuantization.FP16
            )
        )
        
        test_dir = Path("/home/lumi/beautyai/voice_tests/arabic_speaker_tests")
        
        # Test female scenarios
        if female_profile and os.path.exists(female_profile):
            logger.info("ğŸ‘© Testing female speaker scenarios...")
            female_speaker = interface.load_speaker(female_profile)
            
            for scenario, text in beauty_scenarios.items():
                if scenario.startswith("female_"):
                    logger.info(f"   ğŸ¯ {scenario}: {text[:30]}...")
                    
                    output = interface.generate(
                        config=outetts.GenerationConfig(
                            text=text,
                            generation_type=outetts.GenerationType.CHUNKED,
                            speaker=female_speaker,
                            sampler_config=outetts.SamplerConfig(
                                temperature=0.4,
                                top_p=0.9,
                                top_k=50
                            ),
                        )
                    )
                    
                    output_file = test_dir / f"beauty_clinic_{scenario}.wav"
                    output.save(str(output_file))
                    logger.info(f"   âœ… Saved: {output_file.name}")
        
        # Test male scenarios
        if male_profile and os.path.exists(male_profile):
            logger.info("ğŸ‘¨ Testing male speaker scenarios...")
            male_speaker = interface.load_speaker(male_profile)
            
            for scenario, text in beauty_scenarios.items():
                if scenario.startswith("male_"):
                    logger.info(f"   ğŸ¯ {scenario}: {text[:30]}...")
                    
                    output = interface.generate(
                        config=outetts.GenerationConfig(
                            text=text,
                            generation_type=outetts.GenerationType.CHUNKED,
                            speaker=male_speaker,
                            sampler_config=outetts.SamplerConfig(
                                temperature=0.4,
                                top_p=0.9,
                                top_k=50
                            ),
                        )
                    )
                    
                    output_file = test_dir / f"beauty_clinic_{scenario}.wav"
                    output.save(str(output_file))
                    logger.info(f"   âœ… Saved: {output_file.name}")
        
        logger.info("âœ… Beauty clinic scenario testing completed")
        
    except Exception as e:
        logger.error(f"âŒ Beauty clinic testing failed: {e}")

def main():
    """Main function to recreate Arabic speaker profiles."""
    
    print("ğŸ”„ Recreating Arabic Speaker Profiles with Correct Transcriptions")
    print("="*80)
    
    # Check if torch is available for CUDA detection
    try:
        import torch
    except ImportError:
        logger.warning("PyTorch not available, will use CPU for Whisper")
    
    # Clean old profiles
    clean_old_profiles()
    
    # Audio files and their correct transcriptions
    audio_data = {
        "female": {
            "path": "/home/lumi/beautyai/voice_tests/trimmed_audio/arabic_female_15s.wav",
            "transcript": "ÙŠØ¹Ù†ÙŠ Ù‡ÙŠ ÙÙŠ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ§Øª ÙƒØ§Ù†Øª Ø§ÙŠÙˆÙ‡ ØªÙˆØ¬Ø¹ØŒ Ø¨Ø³ Ø§Ù„Ø§Ù† Ù„Ø§ØŒ Ø¨Ø§Ù„Ø¹ÙƒØ³ ÙŠØ¹Ù†ÙŠ ØµØ§Ø± Ø§Ù„Ø´Ø¹ÙˆØ± Ø§Ø¬Ù…Ù„ Ø¨ÙƒØ«ÙŠØ± Ù„Ù…Ø§ Ø§Ù„Ù†Ø§Ø³ ÙŠØ´Ø§Ø±ÙƒÙˆÙ†Ø§ Ø§Ù„ØµÙˆØ± Ø­Ù‚ØªÙ‡Ù…ØŒ ÙƒÙŠÙ Ø§Ù‡Ø¯ÙˆÙ‡Ø§ Ù„Ø§Ø­Ø¯ØŒ Ù„Ø´Ø®Øµ Ø¹Ø²ÙŠØ² Ø§Ùˆ ÙƒÙŠÙ Ù…ÙˆØ¬ÙˆØ¯Ù‡ Ø¹Ù†Ø¯Ù‡Ù… ÙÙŠ Ø§Ù„Ø¨ÙŠØªØŒ ÙŠØ¹Ù†ÙŠ Ø§Ù†Ø§",
            "speaker_name": "arabic_female_corrected"
        },
        "male": {
            "path": "/home/lumi/beautyai/voice_tests/trimmed_audio/arabic_male_15s.wav",
            "transcript": "ÙˆÙÙŠÙ‡Ø§ Ø®ÙŠØ± ÙˆÙ„ÙƒÙ† Ù„ÙƒÙ„ Ù…Ø¬ØªÙ‡Ø¯ Ù†ØµÙŠØ¨ØŒ Ø§Ù„Ø±Ø²Ù‚ Ø±Ø§Ø­ ÙŠØ¬ÙŠÙƒ Ø§Ù† Ø´Ø§Ø¡ Ø§Ù„Ù„Ù‡ Ø¨Ø³ Ø§Ù†Øª Ù…Ø§ ØªÙ‚Ø¹Ø¯ ÙÙŠ Ø§Ù„Ø¨ÙŠØª. ÙØ§Ù†Ø§ Ø§ØªÙ…Ù†Ù‰ Ù…Ù† Ø§Ù„Ù…Ø±Ø´Ø¯ Ø§Ù„Ø³ÙŠØ§Ø­ÙŠ ØªØ¹Ù‚ÙŠØ¨Ø§ Ø¹Ù„Ù‰ Ø³Ø¤Ø§Ù„ÙƒØŒ Ø§Ù†Ù‡ Ù‡Ùˆ ÙŠÙƒÙˆÙ† Ø²ÙŠ Ø§Ù„Ù…Ø±Ø§Ø³Ù„ Ø§Ù„ØªÙ„ÙØ²ÙŠÙˆÙ†ÙŠ. Ø§Ù† ÙŠÙƒÙˆÙ† Ø§Ù…ÙŠÙ† ÙˆØ­Ø±ÙŠØµ Ø¹Ù„Ù‰ Ù†Ù‚Ù„ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ù‡ Ù„Ù…Ø§ ÙŠÙ‚ÙˆÙ„Ù‡Ø§ Ù„Ù„Ø´Ø®Øµ",
            "speaker_name": "arabic_male_corrected"
        }
    }
    
    # Verify audio files exist
    for gender, data in audio_data.items():
        if not os.path.exists(data["path"]):
            logger.error(f"âŒ {gender.capitalize()} audio file not found: {data['path']}")
            logger.info("ğŸ’¡ Run trim_audio_samples.py first")
            return False
    
    created_profiles = {}
    
    # Create speaker profiles with correct transcriptions
    for gender, data in audio_data.items():
        logger.info(f"\nğŸ­ Creating {gender} Arabic speaker profile...")
        
        profile_path = create_arabic_speaker_with_transcript(
            audio_path=data["path"],
            transcript=data["transcript"],
            speaker_name=data["speaker_name"],
            gender=gender
        )
        
        if profile_path:
            created_profiles[gender] = profile_path
            logger.info(f"âœ… {gender.capitalize()} profile created successfully")
        else:
            logger.error(f"âŒ Failed to create {gender} profile")
    
    # Test with beauty clinic scenarios
    if len(created_profiles) > 0:
        logger.info("\nğŸ¥ Testing with beauty clinic scenarios...")
        test_beauty_clinic_scenarios(
            female_profile=created_profiles.get("female"),
            male_profile=created_profiles.get("male")
        )
    
    # Summary
    print(f"\nğŸ“‹ Recreation Summary")
    print("="*80)
    
    if len(created_profiles) == 2:
        print("ğŸ‰ SUCCESS: Both Arabic speaker profiles recreated successfully!")
        print(f"ğŸ‘© Female profile: {created_profiles['female']}")
        print(f"ğŸ‘¨ Male profile: {created_profiles['male']}")
        print(f"ğŸ“ Test files saved in: /home/lumi/beautyai/voice_tests/arabic_speaker_tests/")
        print("\nğŸ’¡ Key improvements:")
        print("   âœ… Used correct transcriptions from your audio files")
        print("   âœ… Profiles now match the actual voice content")
        print("   âœ… Better voice quality and accuracy expected")
        print("   âœ… Tested with beauty clinic scenarios")
        return True
    else:
        print("âŒ PARTIAL SUCCESS: Some profiles failed to create")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
