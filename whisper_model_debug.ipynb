{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a507f9a",
   "metadata": {},
   "source": [
    "# Whisper Model Debug Notebook\n",
    "\n",
    "This notebook allows direct testing of the BeautyAI transcription services to diagnose voice recognition issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8a36f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('/home/lumi/beautyai/backend/src')\n",
    "\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9c4650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import BeautyAI transcription services\n",
    "from beautyai_inference.services.voice.transcription.transcription_factory import create_transcription_service\n",
    "from beautyai_inference.services.voice.transcription.faster_whisper_service import FasterWhisperTranscriptionService\n",
    "from beautyai_inference.services.voice.transcription.transformers_whisper_service import TransformersWhisperService\n",
    "from beautyai_inference.config.voice_config_loader import get_voice_config\n",
    "\n",
    "print(\"‚úÖ BeautyAI transcription services imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9eeff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check voice configuration\n",
    "voice_config = get_voice_config()\n",
    "config_summary = voice_config.get_config_summary()\n",
    "\n",
    "print(\"üîß Voice Configuration Summary:\")\n",
    "print(json.dumps(config_summary, indent=2))\n",
    "\n",
    "# Check which transcription service is being used\n",
    "transcription_service = create_transcription_service()\n",
    "service_type = type(transcription_service).__name__\n",
    "print(f\"\\nüéØ Active Transcription Service: {service_type}\")\n",
    "\n",
    "# Check model info\n",
    "if hasattr(transcription_service, 'get_model_info'):\n",
    "    model_info = transcription_service.get_model_info()\n",
    "    print(f\"üìä Model Info: {model_info}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841ab767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all three transcription services independently\n",
    "def test_service(service_class, service_name):\n",
    "    print(f\"\\nüß™ Testing {service_name}...\")\n",
    "    try:\n",
    "        service = service_class()\n",
    "        \n",
    "        # Try to load model\n",
    "        model_loaded = service.load_whisper_model()\n",
    "        print(f\"   Model loaded: {model_loaded}\")\n",
    "        \n",
    "        if model_loaded:\n",
    "            model_info = service.get_model_info()\n",
    "            print(f\"   Model info: {model_info}\")\n",
    "            \n",
    "        return service, model_loaded\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error: {e}\")\n",
    "        return None, False\n",
    "\n",
    "# Test all services\n",
    "services = {\n",
    "    'Factory Service': (lambda: create_transcription_service(), 'create_transcription_service()'),\n",
    "    'Transformers Service': (TransformersWhisperService, 'TransformersWhisperService'),\n",
    "    'Faster-Whisper Service': (FasterWhisperTranscriptionService, 'FasterWhisperTranscriptionService')\n",
    "}\n",
    "\n",
    "service_results = {}\n",
    "for name, (service_creator, desc) in services.items():\n",
    "    service, loaded = test_service(service_creator, f\"{name} ({desc})\")\n",
    "    service_results[name] = {'service': service, 'loaded': loaded}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fcf432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File upload widget\n",
    "from ipywidgets import FileUpload, VBox, HBox, Button, Output, Dropdown, HTML\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Create upload widget\n",
    "upload_widget = FileUpload(\n",
    "    accept='.wav,.mp3,.webm,.pcm,.ogg,.m4a',\n",
    "    multiple=False,\n",
    "    description='Choose audio file:'\n",
    ")\n",
    "\n",
    "# Language selection\n",
    "language_dropdown = Dropdown(\n",
    "    options=[('Arabic', 'ar'), ('English', 'en'), ('Auto-detect', 'auto')],\n",
    "    value='ar',\n",
    "    description='Language:'\n",
    ")\n",
    "\n",
    "# Service selection\n",
    "available_services = [(name, name) for name, result in service_results.items() if result['loaded']]\n",
    "if not available_services:\n",
    "    available_services = [('No services loaded', 'none')]\n",
    "\n",
    "service_dropdown = Dropdown(\n",
    "    options=available_services,\n",
    "    description='Service:'\n",
    ")\n",
    "\n",
    "# Test button\n",
    "test_button = Button(\n",
    "    description='Test Transcription',\n",
    "    button_style='primary',\n",
    "    icon='microphone'\n",
    ")\n",
    "\n",
    "# Output widget\n",
    "output_widget = Output()\n",
    "\n",
    "# Layout\n",
    "controls = VBox([\n",
    "    HTML(\"<h3>üé§ Audio File Transcription Test</h3>\"),\n",
    "    upload_widget,\n",
    "    HBox([language_dropdown, service_dropdown]),\n",
    "    test_button,\n",
    "    output_widget\n",
    "])\n",
    "\n",
    "display(controls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ccce6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test transcription function\n",
    "def test_transcription(button):\n",
    "    with output_widget:\n",
    "        output_widget.clear_output()\n",
    "        \n",
    "        if not upload_widget.value:\n",
    "            print(\"‚ùå Please upload an audio file first\")\n",
    "            return\n",
    "        \n",
    "        selected_service_name = service_dropdown.value\n",
    "        if selected_service_name == 'none':\n",
    "            print(\"‚ùå No transcription services available\")\n",
    "            return\n",
    "        \n",
    "        selected_language = language_dropdown.value\n",
    "        \n",
    "        print(f\"üîÑ Testing transcription with:\")\n",
    "        print(f\"   Service: {selected_service_name}\")\n",
    "        print(f\"   Language: {selected_language}\")\n",
    "        print(f\"   File: {upload_widget.value[0]['name']}\")\n",
    "        \n",
    "        # Get the service\n",
    "        service = service_results[selected_service_name]['service']\n",
    "        if not service:\n",
    "            print(\"‚ùå Service not available\")\n",
    "            return\n",
    "        \n",
    "        # Get file data\n",
    "        file_info = upload_widget.value[0]\n",
    "        audio_bytes = file_info['content']\n",
    "        file_name = file_info['name']\n",
    "        \n",
    "        print(f\"üìÑ File size: {len(audio_bytes)} bytes\")\n",
    "        \n",
    "        # Determine audio format\n",
    "        file_ext = Path(file_name).suffix.lower()\n",
    "        format_map = {\n",
    "            '.wav': 'wav',\n",
    "            '.mp3': 'mp3', \n",
    "            '.webm': 'webm',\n",
    "            '.pcm': 'pcm',\n",
    "            '.ogg': 'ogg',\n",
    "            '.m4a': 'm4a'\n",
    "        }\n",
    "        audio_format = format_map.get(file_ext, 'unknown')\n",
    "        print(f\"üéµ Detected format: {audio_format}\")\n",
    "        \n",
    "        # Test transcription\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Call transcription\n",
    "            transcript = service.transcribe_audio_bytes(\n",
    "                audio_bytes=audio_bytes,\n",
    "                audio_format=audio_format,\n",
    "                language=selected_language\n",
    "            )\n",
    "            \n",
    "            end_time = time.time()\n",
    "            processing_time = end_time - start_time\n",
    "            \n",
    "            print(f\"\\n‚è±Ô∏è  Processing time: {processing_time:.2f} seconds\")\n",
    "            print(f\"üìù Transcript:\")\n",
    "            print(f\"   '{transcript}'\")\n",
    "            \n",
    "            if transcript:\n",
    "                print(f\"‚úÖ Transcription successful!\")\n",
    "                print(f\"üìä Stats:\")\n",
    "                print(f\"   - Length: {len(transcript)} characters\")\n",
    "                print(f\"   - Words: {len(transcript.split()) if transcript else 0}\")\n",
    "                print(f\"   - Speed: {len(audio_bytes) / 1024 / processing_time:.1f} KB/s\")\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è  Empty transcript returned\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Transcription failed: {str(e)}\")\n",
    "            import traceback\n",
    "            print(f\"üìã Full error:\")\n",
    "            traceback.print_exc()\n",
    "\n",
    "# Connect button to function\n",
    "test_button.on_click(test_transcription)\n",
    "\n",
    "print(\"üéØ Upload an audio file and click 'Test Transcription' to test the whisper models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5df702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment and configuration diagnostics\n",
    "print(\"üîç ENVIRONMENT DIAGNOSTICS\\n\")\n",
    "\n",
    "# Check environment variables\n",
    "env_vars = [\n",
    "    'FORCE_TRANSFORMERS_STT',\n",
    "    'VOICE_STREAMING_ENABLED',\n",
    "    'VOICE_STREAMING_PHASE4',\n",
    "    'CUDA_VISIBLE_DEVICES',\n",
    "    'HF_HOME',\n",
    "    'TRANSFORMERS_CACHE'\n",
    "]\n",
    "\n",
    "print(\"üìã Environment Variables:\")\n",
    "for var in env_vars:\n",
    "    value = os.getenv(var, 'Not set')\n",
    "    print(f\"   {var}: {value}\")\n",
    "\n",
    "# Check GPU availability\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"\\nüñ•Ô∏è  GPU Info:\")\n",
    "    print(f\"   PyTorch version: {torch.__version__}\")\n",
    "    print(f\"   CUDA available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"   CUDA devices: {torch.cuda.device_count()}\")\n",
    "        print(f\"   Current device: {torch.cuda.current_device()}\")\n",
    "        print(f\"   Device name: {torch.cuda.get_device_name()}\")\n",
    "except ImportError:\n",
    "    print(\"\\n‚ö†Ô∏è  PyTorch not available\")\n",
    "\n",
    "# Check model cache\n",
    "cache_paths = [\n",
    "    Path.home() / '.cache' / 'huggingface',\n",
    "    Path('/home/lumi/.cache/huggingface'),\n",
    "    Path('/tmp/cache/huggingface')\n",
    "]\n",
    "\n",
    "print(f\"\\nüìÅ Model Cache Status:\")\n",
    "for cache_path in cache_paths:\n",
    "    if cache_path.exists():\n",
    "        size_mb = sum(f.stat().st_size for f in cache_path.rglob('*') if f.is_file()) / 1024 / 1024\n",
    "        print(f\"   {cache_path}: {size_mb:.1f} MB\")\n",
    "    else:\n",
    "        print(f\"   {cache_path}: Not found\")\n",
    "\n",
    "# Check read-only filesystem issue from logs\n",
    "print(f\"\\n‚ö†Ô∏è  Issues from logs:\")\n",
    "print(f\"   - Read-only filesystem errors detected in journal\")\n",
    "print(f\"   - This may prevent model caching and cause performance issues\")\n",
    "print(f\"   - WebSocket disconnection issues require service restart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93f1368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual test with sample audio data\n",
    "print(\"üî¨ MANUAL AUDIO TEST\\n\")\n",
    "\n",
    "# Generate a test audio signal (sine wave)\n",
    "def generate_test_audio(duration_seconds=2, sample_rate=16000, frequency=440):\n",
    "    \"\"\"Generate a test sine wave audio signal.\"\"\"\n",
    "    t = np.linspace(0, duration_seconds, int(sample_rate * duration_seconds), False)\n",
    "    audio_signal = np.sin(2 * np.pi * frequency * t)\n",
    "    \n",
    "    # Convert to 16-bit PCM\n",
    "    audio_int16 = (audio_signal * 32767).astype(np.int16)\n",
    "    return audio_int16.tobytes()\n",
    "\n",
    "# Test with generated audio\n",
    "print(\"üéµ Generating test audio (440Hz sine wave, 2 seconds)...\")\n",
    "test_audio_bytes = generate_test_audio()\n",
    "\n",
    "print(f\"üìÑ Generated audio: {len(test_audio_bytes)} bytes\")\n",
    "\n",
    "# Test with each working service\n",
    "for service_name, result in service_results.items():\n",
    "    if result['loaded'] and result['service']:\n",
    "        print(f\"\\nüß™ Testing {service_name} with generated audio...\")\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            transcript = result['service'].transcribe_audio_bytes(\n",
    "                audio_bytes=test_audio_bytes,\n",
    "                audio_format='pcm',\n",
    "                language='en'\n",
    "            )\n",
    "            end_time = time.time()\n",
    "            \n",
    "            print(f\"   ‚è±Ô∏è  Time: {end_time - start_time:.2f}s\")\n",
    "            print(f\"   üìù Result: '{transcript}'\")\n",
    "            \n",
    "            if transcript and transcript.strip():\n",
    "                print(f\"   ‚úÖ Service responding (though sine wave shouldn't produce text)\")\n",
    "            else:\n",
    "                print(f\"   ‚ö†Ô∏è  Empty response (expected for sine wave)\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error: {e}\")\n",
    "\n",
    "print(\"\\n‚úÖ Manual test completed\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
