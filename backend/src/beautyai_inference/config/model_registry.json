{
  "default_model": "qwen3-unsloth-q4ks",
  "edge_tts_voices": {
    "arabic": {
      "voices": {
        "male": {
          "primary": "ar-SA-HamedNeural",
          "quality": "high",
          "region": "Saudi Arabia"
        },
        "female": {
          "primary": "ar-SA-ZariyahNeural", 
          "quality": "high",
          "region": "Saudi Arabia"
        }
      },
      "fallbacks": {
        "male": ["ar-EG-ShakirNeural", "ar-AE-HamzaNeural"],
        "female": ["ar-EG-SalmaNeural", "ar-AE-FatimaNeural"]
      }
    },
    "english": {
      "voices": {
        "male": {
          "primary": "en-US-AriaNeural",
          "quality": "high", 
          "region": "United States"
        },
        "female": {
          "primary": "en-US-JennyNeural",
          "quality": "high",
          "region": "United States"
        }
      },
      "fallbacks": {
        "male": ["en-GB-RyanNeural", "en-AU-WilliamNeural"],
        "female": ["en-GB-SoniaNeural", "en-AU-NatashaNeural"]
      }
    }
  },
  "coqui_tts_models": {
    "xtts_v2": {
      "model_name": "tts_models/multilingual/multi-dataset/xtts_v2",
      "languages": ["ar", "en", "es", "fr", "de", "it", "pt", "pl", "tr", "ru", "nl", "cs", "zh-cn", "ja", "hu", "ko", "hi"],
      "features": ["voice_cloning", "multilingual", "emotion_control"],
      "memory_requirements": {
        "min_ram_gb": 8,
        "min_vram_gb": 4,
        "recommended_vram_gb": 8
      }
    }
  },
  "service_configurations": {
    "simple_voice_service": {
      "tts_engine": "edge_tts",
      "stt_engine": "faster_whisper",
      "stt_model": "whisper-turbo-arabic",
      "supported_languages": ["ar", "en"],
      "default_voices": {
        "ar": {
          "male": "ar-SA-HamedNeural",
          "female": "ar-SA-ZariyahNeural"
        },
        "en": {
          "male": "en-US-AriaNeural",
          "female": "en-US-JennyNeural"
        }
      },
      "performance_config": {
        "target_response_time_ms": 1500,
        "enable_caching": true,
        "stream_audio": true,
        "optimize_for_speed": true
      }
    },
    "advanced_voice_service": {
      "tts_engine": "coqui_tts",
      "model": "xtts_v2",
      "supported_languages": ["ar", "en", "es", "fr", "de", "it", "pt", "pl", "tr", "ru", "nl", "cs", "zh-cn", "ja", "hu", "ko", "hi"],
      "features": {
        "voice_cloning": true,
        "emotion_control": true,
        "language_detection": true,
        "content_filtering": true
      },
      "performance_config": {
        "target_response_time_ms": 8000,
        "enable_gpu_optimization": true,
        "quantization": "4bit"
      }
    }
  },
  "service_defaults": {
    "simple_voice_service": {
      "audio_format": "wav",
      "sample_rate": 22050,
      "channels": 1,
      "bit_depth": 16,
      "compression": "none",
      "streaming": {
        "enabled": true,
        "chunk_size": 1024,
        "buffer_size": 4096
      }
    },
    "advanced_voice_service": {
      "audio_format": "wav",
      "sample_rate": 22050,
      "channels": 1,
      "bit_depth": 16,
      "model_loading": {
        "lazy_loading": true,
        "cache_models": true,
        "unload_after_minutes": 10
      }
    }
  },
  "models": {
    "qwen3-model": {
      "model_id": "Qwen/Qwen3-14B",
      "engine_type": "transformers",
      "quantization": "4bit",
      "dtype": "bfloat16",
      "max_new_tokens": 1024,
      "name": "qwen3-model",
      "description": "Qwen3 14B model (4-bit quantized) - Transformers engine",
      "model_architecture": "causal_lm",
      "custom_generation_params": {
        "temperature": 0.1,
        "top_p": 0.95,
        "do_sample": true,
        "repetition_penalty": 1.1
      }
    },
      
    "deepseek-r1-qwen-14b-multilingual": {
      "model_id": "lightblue/DeepSeek-R1-Distill-Qwen-14B-Multilingual",
      "engine_type": "transformers",
      "quantization": "4bit",
      "dtype": "bfloat16",
      "max_new_tokens": 1024,
      "name": "deepseek-r1-qwen-14b-multilingual",
      "description": "DeepSeek R1 Distill Qwen 14B Multilingual - Transformers engine",
      "model_architecture": "causal_lm",
      "custom_generation_params": {
        "temperature": 0.6,
        "top_p": 0.95,
        "do_sample": true,
        "repetition_penalty": 1.1
      }
    },

    "qwen3-official-q4km": {
      "model_id": "Qwen/Qwen3-14B-GGUF",
      "engine_type": "llama.cpp",
      "quantization": "Q4_K_M",
      "dtype": "float16",
      "model_filename": "Qwen3-14B-Q4_K_M.gguf",
      "tokenizer_model_id": "Qwen/Qwen3-14B",
      "max_new_tokens": 256,
      "name": "qwen3-official-q4km",
      "description": "Qwen3 14B Q4_K_M - Official GGUF (8.4GB) - LlamaCpp engine",
      "model_architecture": "causal_lm",
      "custom_generation_params": {
        "temperature": 0.1,
        "top_p": 0.8,
        "do_sample": true,
        "repetition_penalty": 1.05,
        "top_k": 10
      }
    },

    "qwen3-official-q6k": {
      "model_id": "Qwen/Qwen3-14B-GGUF",
      "engine_type": "llama.cpp",
      "quantization": "Q6_K",
      "dtype": "float16",
      "model_filename": "Qwen3-14B-Q6_K.gguf",
      "tokenizer_model_id": "Qwen/Qwen3-14B",
      "max_new_tokens": 256,
      "name": "qwen3-official-q6k",
      "description": "Qwen3 14B Q6_K - Official GGUF high quality (12GB) - LlamaCpp engine",
      "model_architecture": "causal_lm",
      "custom_generation_params": {
        "temperature": 0.1,
        "top_p": 0.8,
        "do_sample": true,
        "repetition_penalty": 1.05,
        "top_k": 10
      }
    },

    "qwen3-unsloth-q4ks": {
      "model_id": "unsloth/Qwen3-14B-GGUF",
      "engine_type": "llama.cpp",
      "quantization": "Q4_K_S",
      "dtype": "float16",
      "model_filename": "Qwen3-14B-Q4_K_S.gguf",
      "tokenizer_model_id": "Qwen/Qwen3-14B",
      "max_new_tokens": 256,
      "name": "qwen3-unsloth-q4ks",
      "description": "Qwen3 14B Q4_K_S - Unsloth optimized fastest (8.0GB) - LlamaCpp engine",
      "model_architecture": "causal_lm",
      "custom_generation_params": {
        "temperature": 0.1,
        "top_p": 0.8,
        "do_sample": true,
        "repetition_penalty": 1.05,
        "top_k": 10
      }
    },

    "qwen3-unsloth-q4km": {
      "model_id": "unsloth/Qwen3-14B-GGUF",
      "engine_type": "llama.cpp",
      "quantization": "Q4_K_M",
      "dtype": "float16",
      "model_filename": "Qwen3-14B-Q4_K_M.gguf",
      "tokenizer_model_id": "Qwen/Qwen3-14B",
      "max_new_tokens": 256,
      "name": "qwen3-unsloth-q4km",
      "description": "Qwen3 14B Q4_K_M - Unsloth optimized balanced (8.4GB) - LlamaCpp engine",
      "model_architecture": "causal_lm",
      "custom_generation_params": {
        "temperature": 0.1,
        "top_p": 0.8,
        "do_sample": true,
        "repetition_penalty": 1.05,
        "top_k": 10
      }
    },

    "qwen3-unsloth-q6k": {
      "model_id": "unsloth/Qwen3-14B-GGUF",
      "engine_type": "llama.cpp",
      "quantization": "Q6_K",
      "dtype": "float16",
      "model_filename": "Qwen3-14B-Q6_K.gguf",
      "tokenizer_model_id": "Qwen/Qwen3-14B",
      "max_new_tokens": 256,
      "name": "qwen3-unsloth-q6k",
      "description": "Qwen3 14B Q6_K - Unsloth optimized high quality (12GB) - LlamaCpp engine",
      "model_architecture": "causal_lm",
      "custom_generation_params": {
        "temperature": 0.1,
        "top_p": 0.8,
        "do_sample": true,
        "repetition_penalty": 1.05,
        "top_k": 10
      }
    },



    "bee1reason-arabic-q4ks": {
      "model_id": "mradermacher/Bee1reason-arabic-Qwen-14B-i1-GGUF",
      "engine_type": "llama.cpp",
      "quantization": "i1-Q4_K_S",
      "dtype": "float16",
      "max_new_tokens": 256,
      "name": "bee1reason-arabic-q4ks",
      "description": "Bee1reason Arabic Qwen 14B i1-Q4_K_S - Fast Arabic reasoning - LlamaCpp engine (cleaned)",
      "model_architecture": "causal_lm",
      "model_filename": "Bee1reason-arabic-Qwen-14B.i1-Q4_K_S.gguf",
      "blob_id": "334c5a6e68b4b18828cc3aeb771a22bd9bcbbca6d55c29ce507f3967c7db1af5",
      "custom_generation_params": {
        "temperature": 0.1,
        "top_p": 0.8,
        "do_sample": true,
        "repetition_penalty": 1.05,
        "top_k": 10
      }
    },

    "bee1reason-arabic-q4km-i1": {
      "model_id": "mradermacher/Bee1reason-arabic-Qwen-14B-i1-GGUF",
      "engine_type": "llama.cpp",
      "quantization": "i1-Q4_K_M",
      "dtype": "float16",
      "max_new_tokens": 256,
      "name": "bee1reason-arabic-q4km-i1",
      "description": "Bee1reason Arabic Qwen 14B i1-Q4_K_M - Balanced Arabic reasoning - LlamaCpp engine (cleaned)",
      "model_architecture": "causal_lm",
      "model_filename": "Bee1reason-arabic-Qwen-14B.i1-Q4_K_M.gguf",
      "blob_id": "b17a5d0aa671fe8fad0abdc9c9914386f9a5b73bc69366500ed8f99b371a4552",
      "custom_generation_params": {
        "temperature": 0.1,
        "top_p": 0.8,
        "do_sample": true,
        "repetition_penalty": 1.05,
        "top_k": 10
      }
    },

    "whisper-turbo-arabic": {
      "model_id": "turbo",
      "engine_type": "faster_whisper",
      "quantization": "int8_float16",
      "dtype": "float16",
      "name": "whisper-turbo-arabic",
      "description": "Fastest Whisper model with Arabic support using Faster-Whisper backend (4x faster)",
      "model_architecture": "whisper",
      "model_filename": null,
      "documentation": "https://github.com/SYSTRAN/faster-whisper",
      "custom_generation_params": {
        "beam_size": 3,
        "temperature": 0.0,
        "condition_on_previous_text": false,
        "use_vad_filter": true,
        "batch_size": 8
      }
    },

    "whisper-large-v3-turbo-arabic": {
      "model_id": "mboushaba/whisper-large-v3-turbo-arabic",
      "engine_type": "transformers",
      "quantization": null,
      "dtype": "float16",
      "name": "whisper-large-v3-turbo-arabic",
      "description": "DEPRECATED: Use whisper-turbo-arabic for better performance",
      "model_architecture": "whisper",
      "model_filename": null,
      "documentation": null,
      "custom_generation_params": null
    },

    "whisper-base": {
      "model_id": "openai/whisper-base",
      "engine_type": "transformers",
      "quantization": null,
      "dtype": "float16",
      "name": "whisper-base",
      "description": "DEPRECATED: Use whisper-turbo-arabic for better performance",
      "model_architecture": "whisper",
      "model_filename": null,
      "documentation": null,
      "custom_generation_params": null
    },

    "edge-tts": {
      "model_id": "microsoft/edge-tts",
      "engine_type": "edge_tts",
      "quantization": null,
      "max_new_tokens": null,
      "dtype": null,
      "name": "edge-tts",
      "description": "PRIMARY TTS: Microsoft Edge TTS for high-quality multilingual text-to-speech (fastest, best quality)",
      "model_architecture": "edge_tts",
      "model_filename": null,
      "documentation": "https://github.com/rany2/edge-tts",
      "custom_generation_params": {
        "emotion": "neutral",
        "speed": 1.0,
        "supported_languages": ["ar", "en", "es", "fr", "de", "it", "pt", "pl", "tr", "ru", "nl", "cs", "zh", "ja", "hu", "ko"]
      }
    },

    "coqui-tts-multilingual": {
      "model_id": "tts_models/multilingual/multi-dataset/xtts_v2",
      "engine_type": "coqui_tts",
      "quantization": null,
      "max_new_tokens": null,
      "dtype": "float16",
      "name": "coqui-tts-multilingual",
      "description": "ADVANCED TTS: Use only when voice cloning is needed (slower than Edge TTS)",
      "model_architecture": "coqui_tts",
      "model_filename": null,
      "documentation": "https://docs.coqui.ai/en/latest/",
      "custom_generation_params": {
        "temperature": 0.7,
        "emotion": "neutral",
        "speed": 1.0,
        "supported_languages": ["ar", "en", "es", "fr", "de", "it", "pt", "pl", "tr", "ru", "nl", "cs", "zh", "ja"],
        "voice_cloning": true,
        "gpu_acceleration": true,
        "multilingual": true
      }
    }
  }
}
